FILE: ./cli-response-handler.go
================================

package main

import (
	"fmt"
	data "owl/data"
	"owl/services"
	"strings"

	"github.com/atotto/clipboard"
	"github.com/charmbracelet/glamour"
	color "github.com/fatih/color"
)

type CliResponseHandler struct {
	Repository data.HistoryRepository
}

func (cli CliResponseHandler) RecievedText(text string, useColor *string) {
	if useColor != nil {
		color.RGB(150, 150, 150).Print(text)
	} else {
		print(text)
	}
}

// All models should call this regardless of if they stream or not.
func (cli CliResponseHandler) FinalText(contextId int64, prompt string, response string) {
	history := data.History{
		ContextId:    contextId,
		Prompt:       prompt,
		Response:     response,
		Abbreviation: "",
		TokenCount:   0,
		//TODO abreviation
		//TODO tokencount
	}

	_, err := cli.Repository.InsertHistory(history)
	if err != nil {
		println(fmt.Sprintf("Error while trying to save history: %s", err))
	}

	code := services.ExtractCodeBlocks(response)
	allCode := strings.Join(code, "\n\n")

	// Copy to clipboard
	err = clipboard.WriteAll(allCode)
	if err != nil {
		fmt.Printf("Error copying to clipboard: %v\n", err)
	}

	out, err := glamour.Render(response, "dark")
	if err != nil {
		println(fmt.Sprintf("%v", err))
	}

	fmt.Println(out)
}


================================

FILE: ./data/history-model.go
================================

package data

import "time"

type Context struct {
	Id           int64     `json:"id"`
	Name         string    `json:"name"`
	History      []History `json:"history"`
	UserId       int64     `json:"userId"`
	Created      time.Time `json:"created"`
	SystemPrompt string    `json:"systemPrompt"`
}

type History struct {
	Id           int64     `json:"id"`
	ContextId    int64     `json:"context_id"`
	Prompt       string    `json:"prompt"`
	Response     string    `json:"response"`
	Abbreviation string    `json:"abreviation"`
	TokenCount   int       `json:"token_count"`
	UserId       int64     `json:"userId"`
	Created      time.Time `json:"created"`
}


================================

FILE: ./data/history-repository.go
================================

package data

type HistoryRepository interface {
	GetContextById(contextId int64) (Context, error)
	InsertHistory(history History) (int64, error)
	InsertContext(context Context) (int64, error)
	GetHistoryByContextId(contextId int64, maxCount int) ([]History, error)
	GetContextByName(name string) (*Context, error)
	GetAllContexts() ([]Context, error)
	DeleteContext(contextId int64) (int64, error)
	DeleteHistory(historyId int64) (int64, error)
	UpdateSystemPrompt(contextId int64, systemPrompt string) error
}


================================

FILE: ./data/postgres-db.go
================================

package data

import (
	"database/sql"
	"log"
	"time"

	_ "github.com/lib/pq"
)

type PostgresHistoryRepository struct {
	db   *sql.DB
	User User
}

func (postgresHistoryRepository *PostgresHistoryRepository) Init(connectionString string) error {
	db, err := sql.Open("postgres", connectionString)
	log.Println("setting up database", db)
	if err != nil {
		return err
	}

	err = db.Ping()
	if err != nil {
		return err
	}

	postgresHistoryRepository.db = db

	return nil
}

func (r *PostgresHistoryRepository) GetContextById(contextId int64) (Context, error) {
	var context Context
	err := r.db.QueryRow("SELECT id, name, user_id FROM context WHERE id = $1 AND user_id = $2", contextId, r.User.Id).
		Scan(&context.Id, &context.Name, &context.UserId, &context.SystemPrompt)
	if err != nil {
		return Context{}, err
	}
	return context, nil
}

func (r *PostgresHistoryRepository) InsertHistory(history History) (int64, error) {
	var id int64
	err := r.db.QueryRow("INSERT INTO history (context_id, prompt, response, abbreviation, token_count, user_id, created) VALUES ($1, $2, $3, $4, $5, $6, $7) RETURNING id",
		history.ContextId, history.Prompt, history.Response, history.Abbreviation, history.TokenCount, history.UserId, time.Now()).
		Scan(&id)
	if err != nil {
		return 0, err
	}
	return id, nil
}

func (r *PostgresHistoryRepository) InsertContext(context Context) (int64, error) {
	var id int64
	err := r.db.QueryRow("INSERT INTO context (name, user_id, system_prompt) VALUES ($1, $2, $3) RETURNING id",
		context.Name, context.UserId, context.SystemPrompt).
		Scan(&id)
	if err != nil {
		return 0, err
	}
	return id, nil
}

func (r *PostgresHistoryRepository) GetHistoryByContextId(contextId int64, maxCount int) ([]History, error) {

	// log.Printf("\nSELECT id, context_id, prompt, response, abbreviation, token_count, user_id, created FROM history WHERE context_id = %s AND user_id = %s ORDER BY created DESC LIMIT %s \n", contextId, r.User.Id, maxCount)

	rows, err := r.db.Query("SELECT id, context_id, prompt, response, abbreviation, token_count, user_id, created FROM history WHERE context_id = $1 AND user_id = $2 ORDER BY created DESC LIMIT $3",
		contextId, r.User.Id, maxCount)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	var histories []History
	for rows.Next() {
		log.Println("row in history response")
		var h History
		err := rows.Scan(&h.Id, &h.ContextId, &h.Prompt, &h.Response, &h.Abbreviation, &h.TokenCount, &h.UserId, &h.Created)
		if err != nil {
			log.Println("error parsing history response", err)
			return nil, err
		}
		histories = append(histories, h)
	}
	return histories, nil
}

func (r *PostgresHistoryRepository) GetContextByName(name string) (*Context, error) {
	var context Context
	err := r.db.QueryRow("SELECT id, name, user_id FROM context WHERE name = $1 AND user_id = $2", name, r.User.Id).
		Scan(&context.Id, &context.Name, &context.UserId, &context.SystemPrompt)
	if err != nil {
		log.Println("err selecting context", err)
		if err == sql.ErrNoRows {
			return nil, nil
		}
		return nil, err
	}
	return &context, nil
}

func (r *PostgresHistoryRepository) GetAllContexts() ([]Context, error) {
	rows, err := r.db.Query("SELECT id, name, user_id FROM context WHERE user_id = $1", r.User.Id)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	var contexts []Context
	for rows.Next() {
		var c Context
		err := rows.Scan(&c.Id, &c.Name, &c.UserId, &c.SystemPrompt)
		if err != nil {
			return nil, err
		}
		contexts = append(contexts, c)
	}
	return contexts, nil
}

func (r *PostgresHistoryRepository) DeleteContext(contextId int64) (int64, error) {
	result, err := r.db.Exec("DELETE FROM context WHERE id = $1 AND user_id = $2", contextId, r.User.Id)
	if err != nil {
		return 0, err
	}
	return result.RowsAffected()
}

func (r *PostgresHistoryRepository) DeleteHistory(historyId int64) (int64, error) {
	result, err := r.db.Exec("DELETE FROM history WHERE id = $1 AND user_id = $2", historyId, r.User.Id)
	if err != nil {
		return 0, err
	}
	return result.RowsAffected()
}

// User CRUD operations

func (r *PostgresHistoryRepository) CreateUser(user User) (int, error) {
	var id int

	log.Println("inserting user", user)
	err := r.db.QueryRow("INSERT INTO users (name, email, slack_id) VALUES ($1, $2, $3) RETURNING id",
		user.Name, user.Email, user.SlackId).
		Scan(&id)
	if err != nil {
		return -1, err
	}
	return id, nil
}

func (r *PostgresHistoryRepository) GetUserById(id string) (*User, error) {
	var user User
	err := r.db.QueryRow("SELECT id, name, email, slack_id FROM users WHERE id = $1", id).
		Scan(&user.Id, &user.Name, &user.Email, &user.SlackId)
	if err != nil {
		if err == sql.ErrNoRows {
			return nil, nil
		}
		return nil, err
	}
	return &user, nil
}

func (r *PostgresHistoryRepository) UpdateUser(user User) error {
	_, err := r.db.Exec("UPDATE users SET name = $1, email = $2, slack_id = $3 WHERE id = $4",
		user.Name, user.Email, user.SlackId, user.Id)
	return err
}

func (r *PostgresHistoryRepository) DeleteUser(id string) error {
	_, err := r.db.Exec("DELETE FROM users WHERE id = $1", id)
	return err
}

func (r *PostgresHistoryRepository) GetUserByEmail(email string) (*User, error) {
	var user User
	err := r.db.QueryRow("SELECT id, name, email, slack_id FROM users WHERE email = $1", email).
		Scan(&user.Id, &user.Name, &user.Email, &user.SlackId)
	if err != nil {
		if err == sql.ErrNoRows {
			return nil, nil
		}
		return nil, err
	}
	return &user, nil
}

func (r *PostgresHistoryRepository) GetUserBySlackId(slackId string) (*User, error) {
	var user User
	err := r.db.QueryRow("SELECT id, name, email, slack_id FROM users WHERE slack_id = $1", slackId).
		Scan(&user.Id, &user.Name, &user.Email, &user.SlackId)
	if err != nil {
		if err == sql.ErrNoRows {
			return nil, nil
		}
		return nil, err
	}
	return &user, nil
}

func (r *PostgresHistoryRepository) UpdateSystemPrompt(contextId int64, systemPrompt string) error {
	_, err := r.db.Exec("UPDATE contexts SET system_prompt = $1 WHERE id = $2",
		systemPrompt, contextId)
	return err
}


================================

FILE: ./data/sqllite-db.go
================================

package data

import (
	"database/sql"
	"fmt"
	"log"

	_ "github.com/mattn/go-sqlite3"
)

func (user User) getUserDb() *sql.DB {

	homeDir, err := getHomeDir()
	if err != nil {
		panic(fmt.Sprintf("did not find home dir for db creation. %s", err))
	}

	path := fmt.Sprintf("%s/.owl/%s.db", homeDir, *user.Name)

	db, err := sql.Open("sqlite3", path)
	if err != nil {
		panic(err)
	}

	// Check if the database is new by querying the sqlite_master table
	var count int
	err = db.QueryRow("SELECT COUNT(*) FROM sqlite_master").Scan(&count)
	if err != nil {
		panic(err)
	}

	// If the database is new (no tables exist), set it up
	if count == 0 {
		user.setupDb(db)
	}

	return db
}

func (user User) setupDb(db *sql.DB) {
	createHistoryTables(db)
	createContextTable(db)
}

func createContextTable(db *sql.DB) {
	createTableQuery := `
         CREATE TABLE IF NOT EXISTS context (
             id INTEGER PRIMARY KEY AUTOINCREMENT,
             name TEXT,
			 system_prompt TEXT
         )
     `

	_, err := db.Exec(createTableQuery)
	if err != nil {
		panic(err)
	}
}

func createHistoryTables(db *sql.DB) {
	createTableQuery := `
         CREATE TABLE IF NOT EXISTS history (
             id INTEGER PRIMARY KEY AUTOINCREMENT,
             context_id INTEGER,
             prompt TEXT,
             response TEXT,
             abreviation TEXT,
             token_count INTEGER
         )
     `
	_, err := db.Exec(createTableQuery)
	if err != nil {
		panic(err)
	}
}

func (user User) InsertContext(context Context) (int64, error) {
	db := user.getUserDb()

	log.Println("inserting context", context.Name, user.Name, user.Id)

	insertQuery := "INSERT INTO context (name, system_prompt) VALUES (?, ?)"
	result, err := db.Exec(insertQuery, context.Name, context.SystemPrompt)
	log.Println("result of context insert", result)

	defer db.Close()
	if err != nil {
		log.Println("insert of context failed", err)
		return 0, err
	}

	contextId, err := result.LastInsertId()
	if err != nil {
		log.Println("insert of context failed", err)
		return 0, err
	}

	return contextId, nil
}

func (user User) GetContextById(contextId int64) (Context, error) {
	db := user.getUserDb()
	defer db.Close()

	selectQuery := "SELECT id, name, system_pronmpt FROM context WHERE id = ?"
	row := db.QueryRow(selectQuery, contextId)

	var context Context
	err := row.Scan(&context.Id, &context.Name, &context.SystemPrompt)
	if err != nil {
		if err == sql.ErrNoRows {
			// return context, fmt.Errorf("context with ID %d not found", contextId)
		}
		return context, err
	}

	return context, nil
}

func (user User) InsertHistory(history History) (int64, error) {
	db := user.getUserDb()

	insertQuery := "INSERT INTO history (context_id, prompt, response, abreviation, token_count) VALUES (?, ?, ?, ?, ?)"
	result, err := db.Exec(insertQuery, history.ContextId, history.Prompt, history.Response, history.Abbreviation, history.TokenCount)
	if err != nil {
		println(err)
		defer db.Close()
		return 0, err
	}

	historyId, err := result.LastInsertId()
	if err != nil {
		println(err)
		defer db.Close()
		return 0, err
	}

	defer db.Close()
	return historyId, nil
}

func (user User) GetHistoryByContextId(contextId int64, maxCount int) ([]History, error) {
	db := user.getUserDb()
	defer db.Close()

	selectQuery := "SELECT id, context_id, prompt, response, abreviation, token_count FROM history WHERE context_id = ? ORDER BY ID DESC LIMIT ?"
	rows, err := db.Query(selectQuery, contextId, maxCount)
	if err != nil {
		return nil, err
	}

	var histories []History
	for rows.Next() {
		var history History
		err := rows.Scan(&history.Id, &history.ContextId, &history.Prompt, &history.Response, &history.Abbreviation, &history.TokenCount)
		if err != nil {
			return nil, err
		}
		histories = append(histories, history)

	}
	for i, j := 0, len(histories)-1; i < j; i, j = i+1, j-1 {
		histories[i], histories[j] = histories[j], histories[i]
	}
	defer rows.Close()

	if err := rows.Err(); err != nil {
		return nil, err
	}

	return histories, nil
}

func (user User) GetContextByName(name string) (*Context, error) {
	db := user.getUserDb()
	defer db.Close()

	selectQuery := "SELECT id, name, system_prompt FROM context WHERE name = ?"
	row := db.QueryRow(selectQuery, name)

	var context Context
	err := row.Scan(&context.Id, &context.Name, &context.SystemPrompt)

	if err != nil {
		return nil, err
	}

	return &context, err
}

func (user User) GetAllContexts() ([]Context, error) {
	db := user.getUserDb()
	defer db.Close()

	rows, err := db.Query("SELECT id, name, system_prompt FROM context")
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	var contexts []Context
	for rows.Next() {
		var context Context
		err := rows.Scan(&context.Id, &context.Name, &context.SystemPrompt)
		if err != nil {
			return nil, err
		}
		contexts = append(contexts, context)
	}

	err = rows.Err()
	if err != nil {
		return nil, err
	}

	return contexts, nil
}

func (user User) DeleteContext(contextId int64) (int64, error) {
	db := user.getUserDb()
	defer db.Close()

	res, err := db.Exec("DELETE FROM context WHERE id = ?", contextId)
	//TODO: should also delete all history connected to the context

	if err != nil {
		return 0, err
	}
	return res.RowsAffected()
}

func (user User) DeleteHistory(historyId int64) (int64, error) {
	db := user.getUserDb()
	defer db.Close()

	res, err := db.Exec("DELETE FROM history WHERE id = ?", historyId)
	if err != nil {
		return 0, err
	}
	return res.RowsAffected()
}

func (user User) UpdateSystemPrompt(contextId int64, systemPrompt string) error {
	db := user.getUserDb()
	defer db.Close()

	fmt.Printf("setting system %s %d :::", systemPrompt, contextId)

	_, err := db.Exec("UPDATE context SET system_prompt = $1 WHERE id = $2",
		systemPrompt, contextId)
	return err
}


================================

FILE: ./data/user-model.go
================================

package data

type User struct {
	Id      int     `json:"id"`
	Name    *string `json:"name"`
	Email   *string `json:"email"`
	SlackId *string `json:"slackId"`
}


================================

FILE: ./data/utils.go
================================

package data

import "os/user"

func getHomeDir() (string, error) {
	usr, err := user.Current()
	if err != nil {
		return "", err
	}
	homeDir := usr.HomeDir
	return homeDir, nil
}


================================

FILE: ./embeddings-response-handler.go
================================

package main

import "fmt"

type EmbeddingsResponseHandler struct {
}

func (rh *EmbeddingsResponseHandler) RecievedText(text string, useColor *string) {
}

func (rh *EmbeddingsResponseHandler) FinalText(contextId int64, prompt string, response string) {
	fmt.Printf("{\"prompt\":%s, \"embedding\": %s}", prompt, response)
}


================================

FILE: ./get-context.go
================================

package main

import (
	"fmt"
	data "owl/data"
)

func getContext(user data.HistoryRepository, system_prompt *string) *data.Context {

	context, _ := user.GetContextByName(context_name)

	if context == nil {
		new_context := data.Context{Name: context_name, SystemPrompt: *system_prompt}
		_, err := user.InsertContext(new_context)
		if err != nil {
			panic(fmt.Sprintf("Could not create a new context with name %s, %s", context_name, err))
		}
	}
	return context
}


================================

FILE: ./http/server.go
================================

package server

import (
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	data "owl/data"
	models "owl/models"
	"owl/services"
)

type server_data struct {
	model               models.Model
	responseHandler     *HttpResponseHandler
	streaming           bool
	db_connectionString string
}

func Run(secure bool, port int, responseHandler *HttpResponseHandler, model models.Model, streaming bool, dbConnectionString string) {

	server_data := server_data{
		model:           model,
		responseHandler: responseHandler,
		streaming:       streaming,
	}

	log.Println("server running on port", port)

	http.HandleFunc("/", server_data.handleRoot)
	http.HandleFunc("/prompt", server_data.handlePrompt)
	http.HandleFunc("/status", server_data.handleStatus)

	var err error
	if secure {
		err = http.ListenAndServeTLS(fmt.Sprintf(":%d", port), "cert.pem", "key.pem", nil)
	} else {
		err = http.ListenAndServe(fmt.Sprintf(":%d", port), nil)
	}

	if err != nil {
		println(fmt.Sprintf("\nerr: %v", err))
	}
}

type owlRequest struct {
	Prompt      string  `json:"prompt"`
	ContextName string  `json:"contextName"`
	User        string  `json:"user"`
	SlackId     *string `json:"slackId"`
}

func parseOwlRequest(r *http.Request) (owlRequest, error) {
	var req owlRequest

	// Check if the Content-Type is application/json
	if r.Header.Get("Content-Type") != "application/json" {
		return req, fmt.Errorf("Content-Type must be application/json")
	}

	// Read the body
	body, err := io.ReadAll(r.Body)
	if err != nil {
		return req, fmt.Errorf("error reading request body: %v", err)
	}
	defer r.Body.Close()

	// Unmarshal the JSON into the owlRequest struct
	err = json.Unmarshal(body, &req)
	if err != nil {
		return req, fmt.Errorf("error parsing JSON: %v", err)
	}

	return req, nil
}

// Helper to get or create user. Should be moved somewhere else?
func getUser(repository *data.PostgresHistoryRepository, req owlRequest) (data.User, error) {
	emailUser, err := repository.GetUserByEmail(req.User)
	if err != nil {
		log.Panic("error trying to find user by email", err)
	}

	if emailUser != nil {
		return *emailUser, nil
	}

	if req.SlackId != nil {
		slackUser, err := repository.GetUserBySlackId(*req.SlackId)
		if err != nil {
			log.Panic("error trying to find user by email", err)
		}
		if slackUser != nil {
			return *slackUser, nil
		}
	}

	newUser := data.User{Name: &req.User, SlackId: req.SlackId, Email: &req.User}
	id, err := repository.CreateUser(newUser)
	if err != nil {
		return newUser, err
	}

	newUser.Id = id

	return newUser, nil
}

func (server_data *server_data) handlePrompt(w http.ResponseWriter, r *http.Request) {
	if r.Method == "POST" {
		// Parse the request body

		req, err := parseOwlRequest(r)
		if err != nil {
			http.Error(w, "Bad input", http.StatusBadRequest)
		}

		repository, ok := server_data.responseHandler.Repository.(*data.PostgresHistoryRepository)
		if !ok {
			log.Fatal("Repository is not of type *PostgresHistoryRepository")
		}

		user, err := getUser(repository, req)
		if err != nil {
			log.Panic("could not get or create user", err)
		}
		repository.User = user

		context, _ := repository.GetContextByName(req.ContextName)
		if context == nil {
			new_context := data.Context{Name: req.ContextName, UserId: int64(user.Id)}
			_, err := repository.InsertContext(new_context)

			if err != nil {
				log.Println(fmt.Sprintf("Could not create a new context with name %s, %s", req.ContextName, err))
			}
		}

		w.Header().Set("Connection", "Keep-Alive")
		w.Header().Set("Transfer-Encoding", "chunked")
		w.WriteHeader(http.StatusOK)

		//trigger awaited query
		server_data.responseHandler.SetResponseWriter(w)
		if server_data.streaming {
			services.StreamedQuery(req.Prompt, server_data.model, server_data.responseHandler.Repository, 5, context, false, "")
		} else {
			services.AwaitedQuery(req.Prompt, server_data.model, server_data.responseHandler.Repository, 5, context, false, "")
		}

	} else {
		http.Error(w, "Method Not Allowed", http.StatusMethodNotAllowed)
	}

}

type HttpResponseHandler struct {
	responseWriter http.ResponseWriter
	Repository     data.HistoryRepository
}

func (httpResponseHandler *HttpResponseHandler) SetResponseWriter(writer http.ResponseWriter) {
	httpResponseHandler.responseWriter = writer
}

func (httpResponseHandler *HttpResponseHandler) RecievedText(text string, useColor *string) {
	fmt.Fprintf(httpResponseHandler.responseWriter, text)
	httpResponseHandler.responseWriter.(http.Flusher).Flush()
}
func (httpResponseHandler *HttpResponseHandler) FinalText(contextId int64, prompt string, response string) {

	repository, ok := httpResponseHandler.Repository.(*data.PostgresHistoryRepository)

	if !ok {
		log.Panic("This needs to be called with a repository that supplies user")
	}

	history := data.History{
		ContextId:    contextId,
		Prompt:       prompt,
		Response:     response,
		Abbreviation: "",
		TokenCount:   0,
		UserId:       int64(repository.User.Id),
		//TODO abreviation
		//TODO tokencount
	}

	_, err := httpResponseHandler.Repository.InsertHistory(history)
	if err != nil {
		println(fmt.Sprintf("Error while trying to save history: %s", err))
	}
	fmt.Fprintf(httpResponseHandler.responseWriter, response)
}

func (server_data *server_data) handleStatus(w http.ResponseWriter, r *http.Request) {
	w.WriteHeader(http.StatusOK)
	fmt.Fprintln(w, "OK")
}

func (server_data *server_data) handleRoot(w http.ResponseWriter, r *http.Request) {
	fmt.Fprintf(w, fmt.Sprintf("%v", server_data.model))
}


================================

FILE: ./logger/logger.go
================================

package logger

import (
	"log"
	"os"

	"github.com/mitchellh/go-homedir"
)

// Global logger - accessible from anywhere
var Debug *log.Logger

// Init sets up the logger - call this from main
func Init(filename string) error {
	expandedPath, err := homedir.Expand(filename)
	if err != nil {
		return err
	}

	f, err := os.OpenFile(expandedPath, os.O_RDWR|os.O_CREATE|os.O_APPEND, 0666)
	if err != nil {
		return err
	}
	Debug = log.New(f, "", log.LstdFlags|log.Lshortfile)
	Debug.Println("Logger initialized")
	return nil
}


================================

FILE: ./main_test.go
================================

package main

import (
	"flag"
	"os"
	"strings"
	"testing"
)

func TestMain(m *testing.M) {
	// Setup test environment
	os.Setenv("OWL_LOCAL_DATABASE", "test_owl")

	// Run tests
	code := m.Run()

	// Cleanup
	os.Unsetenv("OWL_LOCAL_DATABASE")
	os.Exit(code)
}

// resetFlags creates a new flag set and reinitializes our flags
func resetFlags() {
	flag.CommandLine = flag.NewFlagSet(os.Args[0], flag.ExitOnError)
}

func TestFlagParsing(t *testing.T) {
	tests := []struct {
		name     string
		args     []string
		expected map[string]interface{}
	}{
		{
			name: "default values",
			args: []string{},
			expected: map[string]interface{}{
				"context_name": "misc",
				"history":      0,
				"serve":        false,
				"port":         3000,
				"secure":       false,
				"stream":       false,
				"model":        "claude",
				"thinking":     true,
			},
		},
		{
			name: "custom values",
			args: []string{"-prompt", "test prompt", "-model", "grok", "-port", "8080", "-serve"},
			expected: map[string]interface{}{
				"prompt": "test prompt",
				"model":  "grok",
				"port":   8080,
				"serve":  true,
			},
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			// Reset flags for each test
			resetFlags()

			// Set test args
			oldArgs := os.Args
			os.Args = append([]string{"owl"}, tt.args...)
			defer func() { os.Args = oldArgs }()

			flag.Parse()

			// Check expected values
			for key, expected := range tt.expected {
				switch key {
				case "prompt":
					if prompt != expected.(string) {
						t.Errorf("expected prompt %s, got %s", expected, prompt)
					}
				case "context_name":
					if context_name != expected.(string) {
						t.Errorf("expected context_name %s, got %s", expected, context_name)
					}
				case "model":
					if llm_model != expected.(string) {
						t.Errorf("expected model %s, got %s", expected, llm_model)
					}
				case "port":
					if port != expected.(int) {
						t.Errorf("expected port %d, got %d", expected, port)
					}
				case "serve":
					if serve != expected.(bool) {
						t.Errorf("expected serve %t, got %t", expected, serve)
					}
				case "history":
					if history_count != expected.(int) {
						t.Errorf("expected history %d, got %d", expected, history_count)
					}
				case "secure":
					if secure != expected.(bool) {
						t.Errorf("expected secure %t, got %t", expected, secure)
					}
				case "stream":
					if stream != expected.(bool) {
						t.Errorf("expected stream %t, got %t", expected, stream)
					}
				case "thinking":
					if thinking != expected.(bool) {
						t.Errorf("expected thinking %t, got %t", expected, thinking)
					}
				}
			}
		})
	}
}

func TestModelSelection(t *testing.T) {
	tests := []struct {
		modelName string
		isValid   bool
	}{
		{"grok", true},
		{"4o", true},
		{"claude", true},
		{"opus", true},
		{"sonnet", true},
		{"unknown", false}, // should default to claude
	}

	for _, tt := range tests {
		t.Run(tt.modelName, func(t *testing.T) {
			// Reset flags
			resetFlags()

			// Set the model
			oldArgs := os.Args
			os.Args = []string{"owl", "-model", tt.modelName}
			defer func() { os.Args = oldArgs }()

			flag.Parse()

			if llm_model != tt.modelName {
				t.Errorf("expected model %s, got %s", tt.modelName, llm_model)
			}

			// Test that the model name is handled correctly
			switch llm_model {
			case "grok", "4o", "claude", "opus", "sonnet":
				if !tt.isValid {
					t.Errorf("model %s should be invalid but was accepted", tt.modelName)
				}
			default:
				// For unknown models, the system should handle it gracefully
				// (in your main code, it defaults to claude)
			}
		})
	}
}

func TestEnvironmentVariableHandling(t *testing.T) {
	// Test default database name
	os.Unsetenv("OWL_LOCAL_DATABASE")

	db := os.Getenv("OWL_LOCAL_DATABASE")
	if db == "" {
		db = "owl"
	}

	if db != "owl" {
		t.Errorf("expected default db name 'owl', got %s", db)
	}

	// Test custom database name
	os.Setenv("OWL_LOCAL_DATABASE", "custom_db")
	db = os.Getenv("OWL_LOCAL_DATABASE")

	if db != "custom_db" {
		t.Errorf("expected custom db name 'custom_db', got %s", db)
	}

	// Cleanup
	os.Unsetenv("OWL_LOCAL_DATABASE")
}

func TestPromptInputValidation(t *testing.T) {
	tests := []struct {
		name   string
		prompt string
		valid  bool
	}{
		{"empty prompt", "", false},
		{"whitespace only", "   ", false},
		{"valid prompt", "Hello world", true},
		{"multiline prompt", "Hello\nworld", true},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			trimmed := strings.TrimSpace(tt.prompt)
			isEmpty := trimmed == ""

			if tt.valid && isEmpty {
				t.Errorf("expected valid prompt, but got empty after trim")
			}
			if !tt.valid && !isEmpty {
				t.Errorf("expected invalid prompt, but got non-empty after trim")
			}
		})
	}
}

func TestFlagDefaults(t *testing.T) {
	// Reset flags to test defaults
	resetFlags()

	// Parse empty args to get defaults
	oldArgs := os.Args
	os.Args = []string{"owl"}
	defer func() { os.Args = oldArgs }()

	flag.Parse()

	// Test all default values
	defaults := map[string]interface{}{
		"prompt":           "",
		"context_name":     "misc",
		"history_count":    0,
		"serve":            false,
		"port":             3000,
		"secure":           false,
		"stream":           false,
		"embeddings":       false,
		"view":             false,
		"llm_model":        "claude",
		"thinking":         true,
		"stream_thinkning": true,
		"output_thinkning": false,
		"system_prompt":    "",
		"image":            false,
		"pdf":              "",
	}

	// Check each default value
	if prompt != defaults["prompt"].(string) {
		t.Errorf("expected prompt default %s, got %s", defaults["prompt"], prompt)
	}
	if context_name != defaults["context_name"].(string) {
		t.Errorf("expected context_name default %s, got %s", defaults["context_name"], context_name)
	}
	if history_count != defaults["history_count"].(int) {
		t.Errorf("expected history_count default %d, got %d", defaults["history_count"], history_count)
	}
	if serve != defaults["serve"].(bool) {
		t.Errorf("expected serve default %t, got %t", defaults["serve"], serve)
	}
	if port != defaults["port"].(int) {
		t.Errorf("expected port default %d, got %d", defaults["port"], port)
	}
	if llm_model != defaults["llm_model"].(string) {
		t.Errorf("expected llm_model default %s, got %s", defaults["llm_model"], llm_model)
	}
	if thinking != defaults["thinking"].(bool) {
		t.Errorf("expected thinking default %t, got %t", defaults["thinking"], thinking)
	}
}


================================

FILE: ./main.go
================================

package main

import (
	"bufio"
	"log"
	data "owl/data"
	server "owl/http"
	"owl/logger"
	"owl/models"
	claude_model "owl/models/claude"
	grok_model "owl/models/grok"
	openai_4o_model "owl/models/open-ai-4o"
	embeddings_model "owl/models/open-ai-embedings"

	// openai_vision_model "claude/models/open-ai-vision"
	"flag"
	"fmt"
	"os"
	services "owl/services"
	"owl/tui"
	"strings"

	"github.com/charmbracelet/glamour"
	"github.com/joho/godotenv"
)

var (
	DebugLog *log.Logger
)

var (
	prompt           string
	context_name     string
	history_count    int
	serve            bool
	port             int
	secure           bool
	stream           bool
	embeddings       bool
	view             bool
	llm_model        string
	thinking         bool
	stream_thinkning bool
	output_thinkning bool
	system_prompt    string
	image            bool
	pdf              string
	tui_mode         bool
)

func init() {
	if err := logger.Init("~/.owl/debug.log"); err != nil {
		log.Fatal("Failed to initialize logger:", err)
	}

	flag.StringVar(
		&prompt,
		"prompt",
		"",
		"The prompt to use for the conversation",
	)
	flag.StringVar(
		&context_name,
		"context_name",
		"misc",
		"The context to provide for the conversation",
	)
	flag.IntVar(
		&history_count,
		"history",
		0,
		"The number of previous messages to include in the context",
	)
	flag.BoolVar(&serve, "serve", false, "Enable server mode")
	flag.IntVar(&port, "port", 3000, "Port to listen on")
	flag.BoolVar(&secure, "secure", false, "Enable HTTPS")
	flag.BoolVar(&stream, "stream", false, "Enable streaming response")
	flag.BoolVar(&embeddings, "embeddings", false, "Enable embeddings generation (no streaming)")
	flag.StringVar(&llm_model, "model", "claude", "set model used for the call")

	flag.BoolVar(&thinking, "thinking", true, "use thinking in request")
	flag.BoolVar(&stream_thinkning, "stream thinking", true, "stream thinking")
	flag.BoolVar(&output_thinkning, "output thinking", false, "output thinking")
	flag.StringVar(&system_prompt, "system", "", "set a system promt for the context")
	flag.BoolVar(&view, "view", false, "view")
	flag.BoolVar(&image, "image", false, "image (used clipboard as image)")
	flag.StringVar(&pdf, "pdf", "", "path to pdf")
	flag.BoolVar(&tui_mode, "tui", false, "Launch TUI mode")
}

func main() {

	err := godotenv.Load()
	if err != nil {
		log.Print("Error loading .env file")
	}

	flag.Parse()

	if tui_mode {
		launchTUI()
		return
	}

	if system_prompt != "" && context_name != "" {
		db := os.Getenv("OWL_LOCAL_DATABASE")
		if db == "" {
			db = "owl"
		}

		user := data.User{Name: &db}
		context := getContext(user, &system_prompt)

		err := user.UpdateSystemPrompt(context.Id, system_prompt)
		if err != nil {
			println(err)
		}
		return
	}

	if prompt == "" && !serve && !view {
		reader := bufio.NewReader(os.Stdin)
		fmt.Print("Prompt:")
		prompt, _ = reader.ReadString('\n')
		prompt = strings.TrimSpace(prompt)
	}

	if serve {
		projectID := os.Getenv("GCP_PROJECT_ID")

		connectionString := os.Getenv("DB_CONNECTIONSTRING")
		if connectionString == "" {
			secretName := fmt.Sprintf("projects/%s/secrets/owlllm-db-go-cn/versions/latest", projectID)
			connectionString = GetSecretFromGCP(secretName)
		}

		repository := data.PostgresHistoryRepository{}
		err := repository.Init(connectionString)
		if err != nil {
			log.Println("Error initializing db", err)
		}

		httpResponseHandler := &server.HttpResponseHandler{}
		httpResponseHandler.Repository = &repository

		model := claude_model.ClaudeModel{ResponseHandler: httpResponseHandler}
		server.Run(secure, port, httpResponseHandler, &model, stream, connectionString)
	} else if embeddings {
		// Get values from environment variables
		db := os.Getenv("OWL_LOCAL_DATABASE")
		if db == "" {
			db = "owl"
		}

		user := data.User{Name: &db}
		embeddingsResponseHandler := EmbeddingsResponseHandler{}
		model := embeddings_model.OpenAiEmbeddingsModel{ResponseHandler: &embeddingsResponseHandler}

		services.AwaitedQuery(prompt, &model, user, 0, nil, false, "")

	} else if view {
		view_history()
	} else {
		db := os.Getenv("OWL_LOCAL_DATABASE")
		if db == "" {
			db = "owl"
		}

		user := data.User{Name: &db}

		var model models.Model
		cliResponseHandler := CliResponseHandler{Repository: user}

		switch llm_model {
		case "grok":
			model = &grok_model.GrokModel{ResponseHandler: cliResponseHandler}
		case "4o":
			model = &openai_4o_model.OpenAi4oModel{ResponseHandler: cliResponseHandler}
		case "claude":
			model = &claude_model.ClaudeModel{ResponseHandler: cliResponseHandler, UseThinking: thinking, StreamThought: stream_thinkning, OutputThought: output_thinkning}
		case "opus":
			model = &claude_model.ClaudeModel{ResponseHandler: cliResponseHandler, UseThinking: thinking, StreamThought: stream_thinkning, OutputThought: output_thinkning, ModelVersion: "opus"}
		case "sonnet":
			model = &claude_model.ClaudeModel{ResponseHandler: cliResponseHandler, UseThinking: thinking, StreamThought: stream_thinkning, OutputThought: output_thinkning, ModelVersion: "sonnet"}
		default:
			model = &claude_model.ClaudeModel{ResponseHandler: cliResponseHandler, UseThinking: thinking, StreamThought: stream_thinkning, OutputThought: output_thinkning}
		}
		//TODO: Select database
		context := getContext(user, &system_prompt)

		if stream {
			services.StreamedQuery(prompt, model, user, history_count, context, image, pdf)
		} else {
			services.AwaitedQuery(prompt, model, user, history_count, context, image, pdf)
		}
	}

}

func view_history() {
	if context_name == "" {
		panic("No context name to output")
	}

	db := os.Getenv("OWL_LOCAL_DATABASE")
	if db == "" {
		db = "owl"
	}

	user := data.User{Name: &db}

	context, err := user.GetContextByName(context_name)
	if err != nil {
		panic(err)
	}

	count := 100
	if history_count > 0 {
		count = history_count
	}

	history, err := user.GetHistoryByContextId(context.Id, count)
	if err != nil {
		panic(err)
	}

	out, err := glamour.Render(fmt.Sprintf("# %s\n%s", context_name, context.Created), "dark")
	if err != nil {
		println(fmt.Sprintf("%v", err))
	}
	fmt.Println(out)

	for _, h := range history {

		out, err := glamour.Render(fmt.Sprintf("--- \n## Q\n\n %s \n\n## A\n\n %s", h.Prompt, h.Response), "dark")
		if err != nil {
			println(fmt.Sprintf("%v", err))
		}
		fmt.Println(out)
	}
}

func launchTUI() {
	db := os.Getenv("OWL_LOCAL_DATABASE")
	if db == "" {
		db = "owl"
	}

	user := data.User{Name: &db}

	// Setup default model (you can make this configurable)
	cliResponseHandler := CliResponseHandler{Repository: user}
	model := &claude_model.ClaudeModel{
		ResponseHandler: cliResponseHandler,
		UseThinking:     true,
		StreamThought:   false,
		OutputThought:   false,
	}

	config := tui.TUIConfig{
		Repository:   user,
		Model:        model,
		HistoryCount: 10,
	}

	if err := tui.Run(config); err != nil {
		log.Fatal(err)
	}
}


================================

FILE: ./models/claude/claude-data-model.go
================================

package claude_model

type MessageBody struct {
	Model     string         `json:"model"`
	Messages  Message        `json:"messages"`
	MaxTokens int            `json:"max_tokens"`
	System    string         `json:"system"`
	Stream    bool           `json:"stream"`
	Thinking  *ThinkingBlock `json:"thinking,omitempty"`
	Temp      float32        `json:"temperature"`
}

type ThinkingBlock struct {
	Type         string `json:"type"`
	BudgetTokens int    `json:"budget_tokens"`
}

type Message interface {
}

type MessageResponse struct {
	Id         string            `json:"id"`
	Type       string            `json:"type"`
	Role       string            `json:"role"`
	Content    []ResponseMessage `json:"content"`
	Model      string            `json:"model"`
	StopReason string            `json:"stop_reason"`
	Usage      Usage             `json:"usage"`
}

type Usage struct {
	InputTokens  int `json:"input_tokens"`
	OutputTokens int `json:"output_tokens"`
}

type ResponseMessage struct {
	Type string `json:"type"`
	Text string `json:"text"`
}

type Role string

const (
	Apple  Role = "user"
	Banana Role = "assistant"
)

type RequestMessage struct {
	Role    string    `json:"role"`
	Content []Content `json:"content"`
}

type Content interface {
}

type SourceContent struct {
	Type   string `json:"type"`
	Source Source `json:"source"`
}

type TextContent struct {
	Type string `json:"type"`
	Text string `json:"text"`
}

type TextMessage struct {
	Role    string `json:"role"`
	Content string `json:"content"`
}

type SourceMessage struct {
	Role    string        `json:"role"`
	Content SourceContent `json:"content"`
}

// type ImageContent struct {
// 	Type   string `json:"type"`
// 	Source Source `json:"source"`
// }

type MediaType string
type SourceType string

const (
	Image    MediaType  = "image"
	Document SourceType = "document"
)

const (
	Jpeg   MediaType = "image/jpeg"
	Base64 MediaType = "base64"
	Png    MediaType = "image/png"
	Gif    MediaType = "image/gif"
)

type Source struct {
	Type      string    `json:"type"`
	MediaType MediaType `json:"media_type"`
	Data      string    `json:"data"`
}

type StreamEventType string

const (
	ping                StreamEventType = "ping"
	message_stop        StreamEventType = "message_stop"
	message_delta       StreamEventType = "message_delta"
	content_block_delta StreamEventType = "content_block_delta"
	content_block_stop  StreamEventType = "content_block_stop"
)

type StreamResponse struct {
	Event StreamEventType `json:"event"`
	Data  StreamData      `json:"data"`
}

type StreamData struct {
	Type  StreamEventType `json:"type"`
	Index int             `json:"index"`
	Delta StreamDelta     `json:"delta"`
}

type StreamDelta struct {
	Type     string `json:"type"`
	Text     string `json:"text"`
	Thinking string `json:"thinking"`
}


================================

FILE: ./models/claude/claude-model.go
================================

package claude_model

import (
	"bytes"
	"encoding/json"
	"fmt"
	"net/http"
	"os"
	data "owl/data"
	"owl/logger"
	models "owl/models"
	"owl/services"
	"strings"
)

type ClaudeModel struct {
	ResponseHandler   models.ResponseHandler
	Prompt            string
	AccumulatedAnswer string
	ContextId         int64
	ModelVersion      string
	OutputThought     bool
	StreamThought     bool
	UseThinking       bool
}

func (model *ClaudeModel) SetResponseHandler(responseHandler models.ResponseHandler) {
	model.ResponseHandler = responseHandler

}

func (model *ClaudeModel) CreateRequest(context *data.Context, prompt string, streaming bool, history []data.History, image bool, pdf string) *http.Request {
	var model_version string
	switch model.ModelVersion {
	case "3.5-sonnet":
		model_version = "claude-3-5-sonnet-20240620"
	case "3.7-sonnet":
		model_version = "claude-3-7-sonnet-20250219 "
	case "4-sonnet":
		model_version = "claude-sonnet-4-20250514"
	case "opus":
		model_version = "claude-opus-4-20250514"
	case "sonnet":
		model_version = "claude-sonnet-4-5-20250929"
	default:
		model_version = "claude-sonnet-4-5-20250929"
	}
	payload := createCaludePayload(prompt, streaming, history, model_version, model.UseThinking, context, image, pdf)
	model.Prompt = prompt
	model.AccumulatedAnswer = ""
	model.ContextId = context.Id

	request := createClaudeRequest(payload, history)
	// fmt.Printf("\nmodel: \n %v", request)

	return request
}

func (model *ClaudeModel) HandleStreamedLine(line []byte) {
	responseLine := string(line)

	logger.Debug.Println(responseLine)

	if strings.HasPrefix(responseLine, "data: ") {
		var apiResponse StreamData
		data, _ := strings.CutPrefix(responseLine, "data: ")
		if err := json.Unmarshal([]byte(data), &apiResponse); err != nil {
			println(fmt.Sprintf("Error unmarshalling response: %v\n %s", err, line))
		}

		// println(data)

		if apiResponse.Type == content_block_delta {
			model.AccumulatedAnswer = model.AccumulatedAnswer + apiResponse.Delta.Text
			if model.OutputThought {
				model.AccumulatedAnswer = model.AccumulatedAnswer + apiResponse.Delta.Thinking
			}
			model.ResponseHandler.RecievedText(apiResponse.Delta.Text, nil)
			if model.StreamThought {
				color := "grey"
				model.ResponseHandler.RecievedText(apiResponse.Delta.Thinking, &color)
			}
		} else if apiResponse.Type == content_block_stop {
			model.ResponseHandler.RecievedText("\n", nil)
		} else if apiResponse.Type == message_stop {
			model.ResponseHandler.FinalText(model.ContextId, model.Prompt, model.AccumulatedAnswer)
		}
		//TODO: catch the token count response
	}
}

func (model *ClaudeModel) HandleBodyBytes(bytes []byte) {
	var apiResponse MessageResponse
	if err := json.Unmarshal(bytes, &apiResponse); err != nil {
		// Handle error, maybe return or log
		println(fmt.Sprintf("Error unmarshalling response body: %v\n", err))
		logger.Debug.Println(err)
	}
	// log.Fatalf("full resposne: %v", apiResponse)

	logger.Debug.Println("response")
	textIndex := 0
	for i, content := range apiResponse.Content {
		if content.Type == "text" {
			textIndex = i
		}
		logger.Debug.Printf("i: %i, content: %s", i, content)
	}

	model.ResponseHandler.FinalText(model.ContextId, model.Prompt, apiResponse.Content[textIndex].Text)
}

func createCaludePayload(prompt string, streamed bool, history []data.History, model string, useThinking bool, context *data.Context, image bool, pdf string) MessageBody {
	messages := []Message{}
	for _, h := range history {
		messages = append(messages, TextMessage{Role: "user", Content: h.Prompt})
		messages = append(messages, TextMessage{Role: "assistant", Content: h.Response})
	}

	if image {

		image, err := services.GetImageFromClipboard()
		if err != nil {
			panic(fmt.Sprintf("could not get image from clipboard, %v", err))
		}
		base64, err := services.ImageToBase64(image)
		if err != nil {
			panic(fmt.Sprintf("could not get base64 from image, %v", err))
		}

		messages = append(messages, RequestMessage{Role: "user", Content: []Content{
			TextContent{Type: "text", Text: prompt},
			SourceContent{Type: "image", Source: Source{
				Type:      string(Base64),
				MediaType: "image/png",
				Data:      base64,
			}},
		}})
	} else if pdf != "" {
		base64, err := services.ReadPDFAsBase64(pdf)
		if err != nil {
			panic(fmt.Sprintf("could not get base64 from pdf, %v", err))
		}

		messages = append(messages, RequestMessage{Role: "user", Content: []Content{
			TextContent{Type: "text", Text: prompt},
			SourceContent{Type: "document", Source: Source{
				Type:      string(Base64),
				MediaType: "application/pdf",
				Data:      base64,
			}},
		}})
	} else {
		messages = append(messages, RequestMessage{Role: "user", Content: []Content{TextContent{Type: "text", Text: prompt}}})
	}
	// messages = append(messages, TextMessage{Role: "user", Content: prompt})
	payload := MessageBody{
		Model:     model,
		Messages:  messages,
		MaxTokens: 20000,
		Stream:    streamed,
	}
	if context != nil && context.SystemPrompt != "" {
		payload.System = context.SystemPrompt
	}

	if useThinking {
		payload.Thinking = &ThinkingBlock{
			Type:         "enabled",
			BudgetTokens: 2000,
		}
		payload.Temp = 1
	}

	logger.Debug.Println("FULL PAYLOAD:")
	logger.Debug.Printf("\n%s", payload)
	return payload
}

func createClaudeRequest(payload MessageBody, history []data.History) *http.Request {
	apiKey, ok := os.LookupEnv("CLAUDE_API_KEY")
	if !ok {
		panic(fmt.Errorf("Could not fetch api key"))
	}

	jsonpayload, err := json.Marshal(payload)
	if err != nil {
		panic("failed to marshal payload")
	}
	logger.Debug.Println("FULL JSON PAYLOAD:")
	logger.Debug.Printf("\n%s", jsonpayload)

	url := "https://api.anthropic.com/v1/messages"

	req, err := http.NewRequest("POST", url, bytes.NewBuffer(jsonpayload))
	if err != nil {
		panic("failed to create request")
	}

	req.Header.Set("x-api-key", apiKey)
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("anthropic-version", "2023-06-01")

	return req
}


================================

FILE: ./models/grok/grok-data-model.go
================================

package grok_model

type Message struct {
	Role    string `json:"role"`
	Content string `json:"content"`
}
type RequestMessage struct {
	Role    string           `json:"role"`
	Content []RequestContent `json:"content"`
}

type ChatCompletionRequest struct {
	Model     string           `json:"model"`
	Messages  []RequestMessage `json:"messages"`
	Stream    bool             `json:"stream"`
	MaxTokens int              `json:"max_tokens"`
}

type Choice struct {
	Index        int         `json:"index"`
	Message      Message     `json:"message"`
	Logprobs     interface{} `json:"logprobs"`
	FinishReason string      `json:"finish_reason"`
}

type Usage struct {
	PromptTokens     int `json:"prompt_tokens"`
	CompletionTokens int `json:"completion_tokens"`
	TotalTokens      int `json:"total_tokens"`
}

type ChatCompletion struct {
	ID                string   `json:"id"`
	Object            string   `json:"object"`
	Created           int64    `json:"created"`
	Model             string   `json:"model"`
	SystemFingerprint string   `json:"system_fingerprint"`
	Choices           []Choice `json:"choices"`
	Usage             Usage    `json:"usage"`
}

type Delta struct {
	Role    string `json:"role,omitempty"`
	Content string `json:"content,omitempty"`
}

type RequestContent struct {
	Type     string `json:"type"`
	Text     string `json:"text,omitempty"`
	ImageURL Image  `json:"image_url,omitempty"`
}

type Image struct {
	URL string `json:"url"`
}

type ChatCompletionChunkChoice struct {
	Index        int         `json:"index"`
	Delta        Delta       `json:"delta"`
	Logprobs     interface{} `json:"logprobs"`
	FinishReason *string     `json:"finish_reason,omitempty"`
}

type ChatCompletionChunk struct {
	ID                string                      `json:"id"`
	Object            string                      `json:"object"`
	Created           int64                       `json:"created"`
	Model             string                      `json:"model"`
	SystemFingerprint string                      `json:"system_fingerprint"`
	Choices           []ChatCompletionChunkChoice `json:"choices"`
}


================================

FILE: ./models/grok/grok-model.go
================================

package grok_model

import (
	"bytes"
	"encoding/json"
	"fmt"
	"net/http"
	"os"
	"owl/data"
	"owl/models"
	"owl/services"
	"strings"
)

type GrokModel struct {
	ResponseHandler   models.ResponseHandler
	prompt            string
	accumulatedAnswer string
	contextId         int64
}

func (model *GrokModel) SetResponseHandler(responseHandler models.ResponseHandler) {
	model.ResponseHandler = responseHandler

}

func (model *GrokModel) CreateRequest(context *data.Context, prompt string, streaming bool, history []data.History, image bool, pdf string) *http.Request {
	payload := createGrokPayload(prompt, streaming, history, image)
	model.prompt = prompt
	model.accumulatedAnswer = ""
	model.contextId = context.Id
	return createRequest(payload, history, image)
}

func (model *GrokModel) HandleStreamedLine(line []byte) {
	responseLine := string(line)

	// fmt.Printf("\n\n%v\n", responseLine)
	if strings.HasPrefix(responseLine, "data: ") {
		var apiResponse ChatCompletionChunk
		data, _ := strings.CutPrefix(responseLine, "data: ")
		if err := json.Unmarshal([]byte(data), &apiResponse); err != nil {
			// fmt.Printf("Error unmarshalling response: %v\n %s", err, line)
		}

		if len(apiResponse.Choices) > 0 {
			choice := apiResponse.Choices[0]

			model.accumulatedAnswer = model.accumulatedAnswer + choice.Delta.Content
			model.ResponseHandler.RecievedText(choice.Delta.Content, nil)

			if choice.FinishReason != nil {
				fmt.Println(*&choice.FinishReason)
				model.ResponseHandler.FinalText(model.contextId, model.prompt, model.accumulatedAnswer)
			}
		}
	}
}

func (model *GrokModel) HandleBodyBytes(bytes []byte) {
	var apiResponse ChatCompletion
	if err := json.Unmarshal(bytes, &apiResponse); err != nil {
		// Handle error, maybe return or log
		println(fmt.Sprintf("Error unmarshalling response body: %v\n", err))
	}

	model.ResponseHandler.FinalText(model.contextId, model.prompt, apiResponse.Choices[0].Message.Content)
}

func createGrokPayload(prompt string, streamed bool, history []data.History, image bool) ChatCompletionRequest {
	messages := []RequestMessage{}
	for _, h := range history {
		questionContent := RequestContent{Type: "text", Text: h.Prompt}
		messages = append(messages, RequestMessage{Role: "user", Content: []RequestContent{questionContent}})
		answerContent := RequestContent{Type: "text", Text: h.Response}
		messages = append(messages, RequestMessage{Role: "assistant", Content: []RequestContent{answerContent}})
	}

	// messages = append(messages, RequestMessage{Role: "user", Content: []RequestContent{{Type: "text", Text: prompt}}})

	if image {

		image, err := services.GetImageFromClipboard()
		if err != nil {
			panic(fmt.Sprintf("could not get image from clipboard, %s", err))
		}
		base64, err := services.ImageToBase64(image)
		if err != nil {
			panic(fmt.Sprintf("could not get base64 from image, %s", err))
		}

		messages = append(messages, RequestMessage{Role: "user", Content: []RequestContent{
			{Type: "text", Text: prompt},
			{Type: "image_url", ImageURL: Image{
				URL: fmt.Sprintf("data:image/png;base64,%s", base64),
			}},
		}})
	} else {
		messages = append(messages, RequestMessage{Role: "user", Content: []RequestContent{{Type: "text", Text: prompt}}})
	}
	payload := ChatCompletionRequest{
		Model:     "grok-4",
		Stream:    streamed,
		Messages:  messages,
		MaxTokens: 2000,
	}

	return payload
}

func createRequest(payload ChatCompletionRequest, history []data.History, image bool) *http.Request {
	//use gcloud to fetch the token
	apiKey, ok := os.LookupEnv("XAI_API_KEY")
	if !ok {
		panic(fmt.Errorf("Could not fetch api key"))
	}
	// fmt.Printf("\nkey: -%s-", apiKey)

	jsonpayload, err := json.Marshal(payload)
	if err != nil {
		panic("failed to marshal payload")
	}

	url := "https://api.x.ai/v1/chat/completions"
	req, err := http.NewRequest("POST", url, bytes.NewBuffer(jsonpayload))
	if err != nil {
		panic(fmt.Errorf("failed to create request: %v", err))
	}

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", fmt.Sprintf("Bearer %s", apiKey))

	return req
}


================================

FILE: ./models/model.go
================================

package models

import (
	"net/http"
	"owl/data"
)

type Model interface {
	CreateRequest(context *data.Context, prompt string, streaming bool, history []data.History, image bool, pdf string) *http.Request
	HandleStreamedLine(line []byte)
	HandleBodyBytes(bytes []byte)
	SetResponseHandler(responseHandler ResponseHandler)
}


================================

FILE: ./models/open-ai-4o/open-ai-o-data-model.go
================================

package openai_4o_model

type Message struct {
	Role    string `json:"role"`
	Content string `json:"content"`
}
type RequestMessage struct {
	Role    string           `json:"role"`
	Content []RequestContent `json:"content"`
}

type ChatCompletionRequest struct {
	Model     string           `json:"model"`
	Messages  []RequestMessage `json:"messages"`
	Stream    bool             `json:"stream"`
	MaxTokens int              `json:"max_tokens"`
}

type Choice struct {
	Index        int         `json:"index"`
	Message      Message     `json:"message"`
	Logprobs     interface{} `json:"logprobs"`
	FinishReason string      `json:"finish_reason"`
}

type Usage struct {
	PromptTokens     int `json:"prompt_tokens"`
	CompletionTokens int `json:"completion_tokens"`
	TotalTokens      int `json:"total_tokens"`
}

type ChatCompletion struct {
	ID                string   `json:"id"`
	Object            string   `json:"object"`
	Created           int64    `json:"created"`
	Model             string   `json:"model"`
	SystemFingerprint string   `json:"system_fingerprint"`
	Choices           []Choice `json:"choices"`
	Usage             Usage    `json:"usage"`
}

type Delta struct {
	Role    string `json:"role,omitempty"`
	Content string `json:"content,omitempty"`
}

type RequestContent struct {
	Type     string `json:"type"`
	Text     string `json:"text,omitempty"`
	ImageURL Image  `json:"image_url,omitempty"`
}

type Image struct {
	URL string `json:"url"`
}

type ChatCompletionChunkChoice struct {
	Index        int         `json:"index"`
	Delta        Delta       `json:"delta"`
	Logprobs     interface{} `json:"logprobs"`
	FinishReason *string     `json:"finish_reason,omitempty"`
}

type ChatCompletionChunk struct {
	ID                string                      `json:"id"`
	Object            string                      `json:"object"`
	Created           int64                       `json:"created"`
	Model             string                      `json:"model"`
	SystemFingerprint string                      `json:"system_fingerprint"`
	Choices           []ChatCompletionChunkChoice `json:"choices"`
}


================================

FILE: ./models/open-ai-4o/open-ai-o-model.go
================================

package openai_4o_model

import (
	"bytes"
	"encoding/json"
	"fmt"
	"net/http"
	"os"
	"owl/data"
	"owl/models"
	services "owl/services"
	"strings"
)

type OpenAi4oModel struct {
	ResponseHandler   models.ResponseHandler
	prompt            string
	accumulatedAnswer string
	contextId         int64
}

func (model *OpenAi4oModel) SetResponseHandler(responseHandler models.ResponseHandler) {
	model.ResponseHandler = responseHandler

}

func (model *OpenAi4oModel) CreateRequest(context *data.Context, prompt string, streaming bool, history []data.History, image bool, pdf string) *http.Request {
	payload := createOpenaiPayload(prompt, streaming, history, image)
	model.prompt = prompt
	model.accumulatedAnswer = ""
	model.contextId = context.Id
	return createRequest(payload, history)
}

func (model *OpenAi4oModel) HandleStreamedLine(line []byte) {
	responseLine := string(line)

	// fmt.Printf("\n\n%v\n", responseLine)
	if strings.HasPrefix(responseLine, "data: ") {
		var apiResponse ChatCompletionChunk
		data, _ := strings.CutPrefix(responseLine, "data: ")
		if err := json.Unmarshal([]byte(data), &apiResponse); err != nil {
			// fmt.Printf("Error unmarshalling response: %v\n %s", err, line)
		}

		if len(apiResponse.Choices) > 0 {
			choice := apiResponse.Choices[0]

			model.accumulatedAnswer = model.accumulatedAnswer + choice.Delta.Content
			model.ResponseHandler.RecievedText(choice.Delta.Content, nil)

			if choice.FinishReason != nil {
				fmt.Println(*&choice.FinishReason)
				model.ResponseHandler.FinalText(model.contextId, model.prompt, model.accumulatedAnswer)
			}
		}
	}
}

func (model *OpenAi4oModel) HandleBodyBytes(bytes []byte) {
	var apiResponse ChatCompletion
	if err := json.Unmarshal(bytes, &apiResponse); err != nil {
		// Handle error, maybe return or log
		println(fmt.Sprintf("Error unmarshalling response body: %v\n", err))
	}

	model.ResponseHandler.FinalText(model.contextId, model.prompt, apiResponse.Choices[0].Message.Content)
}

func createOpenaiPayload(prompt string, streamed bool, history []data.History, image bool) ChatCompletionRequest {
	messages := []RequestMessage{}
	for _, h := range history {
		questionContent := RequestContent{Type: "text", Text: h.Prompt}
		messages = append(messages, RequestMessage{Role: "user", Content: []RequestContent{questionContent}})
		answerContent := RequestContent{Type: "text", Text: h.Response}
		messages = append(messages, RequestMessage{Role: "assistant", Content: []RequestContent{answerContent}})
	}

	if image {

		image, err := services.GetImageFromClipboard()
		if err != nil {
			panic(fmt.Sprintf("could not get image from clipboard, %s", err))
		}
		base64, err := services.ImageToBase64(image)
		if err != nil {
			panic(fmt.Sprintf("could not get base64 from image, %s", err))
		}

		messages = append(messages, RequestMessage{Role: "user", Content: []RequestContent{
			{Type: "text", Text: prompt},
			{Type: "image_url", ImageURL: Image{
				URL: fmt.Sprintf("data:image/png;base64,%s", base64),
			}},
		}})
	} else {
		messages = append(messages, RequestMessage{Role: "user", Content: []RequestContent{{Type: "text", Text: prompt}}})
	}
	payload := ChatCompletionRequest{
		Model:     "gpt-4o",
		Stream:    streamed,
		Messages:  messages,
		MaxTokens: 15000,
	}

	return payload
}

func createRequest(payload ChatCompletionRequest, history []data.History) *http.Request {
	//use gcloud to fetch the token
	apiKey, ok := os.LookupEnv("OPENAI_API_KEY")
	if !ok {
		panic(fmt.Errorf("Could not fetch api key"))
	}
	// fmt.Printf("\nkey: -%s-", apiKey)

	jsonpayload, err := json.Marshal(payload)
	if err != nil {
		panic("failed to marshal payload")
	}

	url := "https://api.openai.com/v1/chat/completions"
	req, err := http.NewRequest("POST", url, bytes.NewBuffer(jsonpayload))
	if err != nil {
		panic(fmt.Errorf("failed to create request: %v", err))
	}

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", fmt.Sprintf("Bearer %s", apiKey))

	return req
}


================================

FILE: ./models/open-ai-embedings/embeddings-data-model.go
================================

package open_ai_embedings

type Payload struct {
	Input          string `json:"input"`
	Model          string `json:"model"`
	EncodingFormat string `json:"encoding_format"`
	// Dimensions     int    `json:"dimensions"`
}

type Response struct {
	Object string      `json:"object"`
	Data   []Embedding `json:"data"`
	Model  string      `json:"model"`
	Usage  Usage       `json:"usage"`
}

type Usage struct {
	PromptTokens int `json:"promptTokens"`
	TotalTokens  int `json:"totalTokens"`
}

type Embedding struct {
	Object    string    `json:"object"`
	Embedding []float32 `json:"embedding"`
	Index     int       `json:"index"`
}


================================

FILE: ./models/open-ai-embedings/embeddings-model.go
================================

package open_ai_embedings

import (
	"bytes"
	"encoding/json"
	"fmt"
	"net/http"
	"os"
	"owl/data"
	models "owl/models"
)

type OpenAiEmbeddingsModel struct {
	ResponseHandler models.ResponseHandler
	prompt          string
}

func (model *OpenAiEmbeddingsModel) SetResponseHandler(responseHandler models.ResponseHandler) {
	model.ResponseHandler = responseHandler

}

func (model *OpenAiEmbeddingsModel) CreateRequest(context *data.Context, prompt string, streaming bool, history []data.History, image bool, pdf string) *http.Request {
	payload := createPayload(prompt, streaming, history)
	model.prompt = prompt
	return createRequest(payload, history, image)
}

func createPayload(prompt string, streamed bool, history []data.History) Payload {
	payload := Payload{
		Model:          "text-embedding-ada-002",
		Input:          prompt,
		EncodingFormat: "float",
		// Dimensions:     69,
	}

	return payload
}

func createRequest(payload Payload, history []data.History, image bool) *http.Request {
	//use gcloud to fetch the token
	apiKey, ok := os.LookupEnv("OPENAI_API_KEY")
	if !ok {
		panic(fmt.Errorf("Could not fetch api key"))
	}

	jsonpayload, err := json.Marshal(payload)
	if err != nil {
		panic("failed to marshal payload")
	}

	url := "https://api.openai.com/v1/embeddings"
	req, err := http.NewRequest("POST", url, bytes.NewBuffer(jsonpayload))
	if err != nil {
		panic(fmt.Errorf("failed to create request: %v", err))
	}

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", fmt.Sprintf("Bearer %s", apiKey))

	return req
}

func (model *OpenAiEmbeddingsModel) HandleStreamedLine(line []byte) {
}

func (model *OpenAiEmbeddingsModel) HandleBodyBytes(bytes []byte) {
	var apiResponse Response
	if err := json.Unmarshal(bytes, &apiResponse); err != nil {
		// Handle error, maybe return or log
		println(fmt.Sprintf("Error unmarshalling response body: %v\n", err))
	}

	//TODO: Why is data indexed
	if len(apiResponse.Data) > 1 {
		println("Multiple data in Data array. Only handling 1 at the moment")
	}

	embeddingsArray, err := json.Marshal(apiResponse.Data[0].Embedding)
	if err != nil {
		println(err)
	}

	model.ResponseHandler.FinalText(0, model.prompt, string(embeddingsArray))
}


================================

FILE: ./models/open-ai-vision/openai-vision-data-model.go
================================

package openai_vision_model

type Payload struct {
	Model     string    `json:"model"`
	Messages  []Message `json:"messages"`
	MaxTokens int       `json:"max_tokens"`
	Stream    bool      `json:"stream"`
}

type Message struct {
	Role    string    `json:"role"`
	Content []Content `json:"content"`
}

type Content struct {
	Type     string `json:"type"`
	Text     string `json:"text,omitempty"`
	ImageURL Image  `json:"image_url,omitempty"`
}

type Image struct {
	URL string `json:"url"`
}

type ApiResponse struct {
	ID      string `json:"id"`
	Object  string `json:"object"`
	Created int64  `json:"created"`
	Model   string `json:"model"`
	Usage   struct {
		PromptTokens     int `json:"prompt_tokens"`
		CompletionTokens int `json:"completion_tokens"`
		TotalTokens      int `json:"total_tokens"`
	} `json:"usage"`
	Choices []struct {
		Message struct {
			Role    string `json:"role"`
			Content string `json:"content"`
		} `json:"message"`
		FinishDetails struct {
			Type string `json:"type"`
			Stop string `json:"stop"`
		} `json:"finish_details"`
		Index int `json:"index"`
	} `json:"choices"`
}

//StreamData response example for stop reason
// {
//   "id": "chatcmpl-97f5iA568rrc7H7oPVEuFbXJLoI6f",
//   "object": "chat.completion.chunk",
//   "created": 1711613278,
//   "model": "gpt-4-1106-vision-preview",
//   "system_fingerprint": null,
//   "choices": [
//     {
//       "index": 0,
//       "delta": {},
//       "logprobs": null,
//       "finish_reason": "stop"
//     }
//   ]
// }

type StreamData struct {
	Choices []Choice `json:"choices"`
}

type Choice struct {
	Delta        Delta   `json:"delta"`
	FinishReason *string `json:"finish_reason"`
}

type Delta struct {
	Content string `json:"content"`
}


================================

FILE: ./models/open-ai-vision/openai-vision-model.go
================================

package openai_vision_model

import (
	"bytes"
	"encoding/json"
	"fmt"
	"net/http"
	"os"
	"owl/data"
	"owl/models"
	"strings"
)

type OpenAiModel struct {
	ResponseHandler   models.ResponseHandler
	prompt            string
	accumulatedAnswer string
	contextId         int64
}

func (model *OpenAiModel) SetResponseHandler(responseHandler models.ResponseHandler) {
	model.ResponseHandler = responseHandler

}

func (model *OpenAiModel) CreateRequest(context data.Context, prompt string, streaming bool, history []data.History, image bool, pdf string) *http.Request {
	payload := createOpenaiPayload(prompt, streaming, history)
	model.prompt = prompt
	model.accumulatedAnswer = ""
	model.contextId = context.Id
	return createRequest(payload, history)
}

func (model *OpenAiModel) HandleStreamedLine(line []byte) {
	responseLine := string(line)

	// fmt.Printf("\n\n%v\n", responseLine)
	if strings.HasPrefix(responseLine, "data: ") {
		var apiResponse StreamData
		data, _ := strings.CutPrefix(responseLine, "data: ")
		if err := json.Unmarshal([]byte(data), &apiResponse); err != nil {
			// fmt.Printf("Error unmarshalling response: %v\n %s", err, line)
		}

		if len(apiResponse.Choices) > 0 {
			choice := apiResponse.Choices[0]

			model.accumulatedAnswer = model.accumulatedAnswer + choice.Delta.Content
			model.ResponseHandler.RecievedText(choice.Delta.Content, nil)

			if choice.FinishReason != nil {
				fmt.Println(*choice.FinishReason)
				model.ResponseHandler.FinalText(model.contextId, model.prompt, model.accumulatedAnswer)
			}
		}
	}
}

func (model *OpenAiModel) HandleBodyBytes(bytes []byte) {
	var apiResponse ApiResponse
	if err := json.Unmarshal(bytes, &apiResponse); err != nil {
		// Handle error, maybe return or log
		println(fmt.Sprintf("Error unmarshalling response body: %v\n", err))
	}

	model.ResponseHandler.FinalText(model.contextId, model.prompt, apiResponse.Choices[0].Message.Content)
}

func createOpenaiPayload(prompt string, streamed bool, history []data.History) Payload {
	messages := []Message{}
	for _, h := range history {
		questionContent := Content{Type: "text", Text: h.Prompt}
		messages = append(messages, Message{Role: "user", Content: []Content{questionContent}})
		answerContent := Content{Type: "text", Text: h.Response}
		messages = append(messages, Message{Role: "assistant", Content: []Content{answerContent}})
	}

	messages = append(messages, Message{Role: "user", Content: []Content{{Type: "text", Text: prompt}}})
	payload := Payload{
		Model:     "gpt-4-vision-preview",
		Stream:    streamed,
		Messages:  messages,
		MaxTokens: 2000,
	}

	return payload
}

func createRequest(payload Payload, history []data.History) *http.Request {
	//use gcloud to fetch the token
	apiKey, ok := os.LookupEnv("OPENAI_API_KEY")
	if !ok {
		panic(fmt.Errorf("Could not fetch api key"))
	}
	// fmt.Printf("\nkey: -%s-", apiKey)

	jsonpayload, err := json.Marshal(payload)
	if err != nil {
		panic("failed to marshal payload")
	}

	url := "https://api.openai.com/v1/chat/completions"
	req, err := http.NewRequest("POST", url, bytes.NewBuffer(jsonpayload))
	if err != nil {
		panic(fmt.Errorf("failed to create request: %v", err))
	}

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", fmt.Sprintf("Bearer %s", apiKey))

	return req
}


================================

FILE: ./models/response-handler.go
================================

package models

type ResponseHandler interface {
	RecievedText(text string, color *string)
	FinalText(contextId int64, prompt string, response string)
	// func recievedImage(encoded string)
}


================================

FILE: ./models/vertex-claude/claude-data-model.go
================================

package vertex_claude_model

type Message interface {
}

type MessageResponse struct {
	Id         string            `json:"id"`
	Type       string            `json:"type"`
	Role       string            `json:"role"`
	Content    []ResponseMessage `json:"content"`
	Model      string            `json:"model"`
	StopReason string            `json:"stop_reason"`
	Usage      Usage             `json:"usage"`
}

type Usage struct {
	InputTokens  int `json:"input_tokens"`
	OutputTokens int `json:"output_tokens"`
}

type ResponseMessage struct {
	Type string `json:"type"`
	Text string `json:"text"`
}

type Role string

const (
	Apple  Role = "user"
	Banana Role = "assistant"
)

type TextMessage struct {
	Role    string `json:"role"`
	Content string `json:"content"`
}

type ImageMessage struct {
	Role    string       `json:"role"`
	Content ImageContent `json:"content"`
}

type ImageContent struct {
	Type   string `json:"type"`
	Source Source `json:"source"`
}

type MediaType string

const (
	Jpeg   MediaType = "image/jpeg"
	Base64 MediaType = "base64"
	Png    MediaType = "image/png"
	Gif    MediaType = "image/gif"
)

type Source struct {
	Type      string    `json:"type"`
	MediaType MediaType `json:"media_type"`
	Data      string    `json:"data"`
}

type StreamEventType string

const (
	ping                StreamEventType = "ping"
	message_stop        StreamEventType = "message_stop"
	message_delta       StreamEventType = "message_delta"
	content_block_delta StreamEventType = "content_block_delta"
	content_block_stop  StreamEventType = "content_block_stop"
)

type StreamResponse struct {
	Event StreamEventType `json:"event"`
	Data  StreamData      `json:"data"`
}

type StreamData struct {
	Type  StreamEventType `json:"type"`
	Index int             `json:"index"`
	Delta StreamDelta     `json:"delta"`
}

type StreamDelta struct {
	Type string `json:"type"`
	Text string `json:"text"`
}
type VertexMessageBody struct {
	AnthropicVersion string  `json:"anthropic_version"`
	Messages         Message `json:"messages"`
	MaxTokens        int     `json:"max_tokens"`
	System           string  `json:"system"`
	Stream           bool    `json:"stream"`
	Temp             float32 `json:"temperature"`
}


================================

FILE: ./models/vertex-claude/vertex-claude-model.go
================================

package vertex_claude_model

import (
	"bytes"
	"encoding/json"
	"fmt"
	"net/http"
	"os/exec"
	data "owl/data"
	models "owl/models"
	"strings"
)

type ClaudeModel struct {
	ResponseHandler   models.ResponseHandler
	prompt            string
	accumulatedAnswer string
	contextId         int64
}

func (model *ClaudeModel) SetResponseHandler(responseHandler models.ResponseHandler) {
	model.ResponseHandler = responseHandler

}

func (model *ClaudeModel) CreateRequest(contextId int64, prompt string, streaming bool, history []data.History, image bool, pdf string) *http.Request {
	payload := createClaudePayload(prompt, streaming, history)
	model.prompt = prompt
	model.accumulatedAnswer = ""
	model.contextId = contextId
	return createClaudeRequest(payload, history)
}

func (model *ClaudeModel) HandleStreamedLine(line []byte) {
	responseLine := string(line)

	if strings.HasPrefix(responseLine, "data: ") {
		var apiResponse StreamData
		data, _ := strings.CutPrefix(responseLine, "data: ")
		if err := json.Unmarshal([]byte(data), &apiResponse); err != nil {
			println(fmt.Sprintf("Error unmarshalling response: %v\n %s", err, line))
		}

		if apiResponse.Type == content_block_delta {
			model.accumulatedAnswer = model.accumulatedAnswer + apiResponse.Delta.Text
			model.ResponseHandler.RecievedText(apiResponse.Delta.Text, nil)
		} else if apiResponse.Type == message_stop {
			model.ResponseHandler.FinalText(model.contextId, model.prompt, model.accumulatedAnswer)
		}
		//TODO: catch the token count response
	} else {
		println(fmt.Sprintf("%v", responseLine))
	}
}

func (model *ClaudeModel) HandleBodyBytes(bytes []byte) {
	var apiResponse MessageResponse
	if err := json.Unmarshal(bytes, &apiResponse); err != nil {
		// Handle error, maybe return or log
		fmt.Printf("Error unmarshalling response body: %v\n", err)
	}

	model.ResponseHandler.FinalText(model.contextId, model.prompt, apiResponse.Content[0].Text)
}

func createClaudePayload(prompt string, streamed bool, history []data.History) VertexMessageBody {
	messages := []Message{}
	for _, h := range history {
		messages = append(messages, TextMessage{Role: "user", Content: h.Prompt})
		messages = append(messages, TextMessage{Role: "assistant", Content: h.Response})
	}
	messages = append(messages, TextMessage{Role: "user", Content: prompt})
	payload := VertexMessageBody{
		AnthropicVersion: "vertex-2023-10-16",
		Messages:         messages,
		MaxTokens:        2000,
		Stream:           streamed,
	}

	return payload
}

func createClaudeRequest(payload VertexMessageBody, history []data.History) *http.Request {
	//use gcloud to fetch the token
	cmd := exec.Command("gcloud", "auth", "print-access-token")
	apiKeyBytes, err := cmd.CombinedOutput()
	//apiKey, ok := os.LookupEnv("VERTEX_CLAUDE_API_KEY")
	apiKey := strings.TrimSpace(string(apiKeyBytes))
	if err != nil {
		panic(fmt.Errorf("Could not fetch api key %v", err))
	}

	jsonpayload, err := json.Marshal(payload)
	if err != nil {
		panic("failed to marshal payload")
	}

	project_id := "sandbox-416509"
	model := "claude-3-sonnet@20240229"
	location := "us-central1"

	url := fmt.Sprintf("https://%s-aiplatform.googleapis.com/v1/projects/%s/locations/%s/publishers/anthropic/models/%s:streamRawPredict", location, project_id, location, model)

	req, err := http.NewRequest("POST", url, bytes.NewBuffer(jsonpayload))
	if err != nil {
		panic("failed to create request")
	}

	req.Header.Set("Authorization", fmt.Sprintf("Bearer %s", apiKey))
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("anthropic-version", "vertex-2023-10-16")

	return req
}


================================

FILE: ./pdf_test.go
================================

package main

import (
	"encoding/base64"
	"fmt"
	"os"
	"path/filepath"
	"testing"
)

func TestPDFOperations(t *testing.T) {
	// Create a mock PDF file for testing
	mockPDFContent := "%PDF-1.4\n1 0 obj\n<< /Type /Catalog /Pages 2 0 R >>\nendobj\n"
	mockPDFPath := "test_helpers/test_data/test.pdf"

	// Ensure test directory exists
	os.MkdirAll("test_helpers/test_data", 0755)

	// Create mock PDF
	err := os.WriteFile(mockPDFPath, []byte(mockPDFContent), 0644)
	if err != nil {
		t.Fatalf("Failed to create test PDF: %v", err)
	}
	defer os.Remove(mockPDFPath)

	t.Run("ReadPDFAsBase64_Success", func(t *testing.T) {
		result, err := ReadPDFAsBase64(mockPDFPath)
		if err != nil {
			t.Errorf("Expected no error, got: %v", err)
		}

		// Verify base64 encoding
		decoded, err := base64.StdEncoding.DecodeString(result)
		if err != nil {
			t.Errorf("Result is not valid base64: %v", err)
		}

		if string(decoded) != mockPDFContent {
			t.Errorf("Decoded content doesn't match original")
		}
	})

	t.Run("ReadPDFAsBase64_FileNotExists", func(t *testing.T) {
		_, err := ReadPDFAsBase64("nonexistent.pdf")
		if err == nil {
			t.Error("Expected error for nonexistent file")
		}
	})

	t.Run("ReadPDFAsBase64_NotPDF", func(t *testing.T) {
		txtPath := "test_helpers/test_data/test.txt"
		os.WriteFile(txtPath, []byte("test"), 0644)
		defer os.Remove(txtPath)

		_, err := ReadPDFAsBase64(txtPath)
		if err == nil {
			t.Error("Expected error for non-PDF file")
		}
	})
}

// Add the PDF reading function if it doesn't exist
func ReadPDFAsBase64(filePath string) (string, error) {
	// Check if file exists and is a PDF
	if filepath.Ext(filePath) != ".pdf" {
		return "", fmt.Errorf("file is not a PDF: %s", filePath)
	}

	// Read the file
	fileBytes, err := os.ReadFile(filePath)
	if err != nil {
		return "", fmt.Errorf("error reading file: %v", err)
	}

	// Convert to base64
	base64String := base64.StdEncoding.EncodeToString(fileBytes)

	return base64String, nil
}


================================

FILE: ./secrets.go
================================

package main

import (
	"context"
	"log"

	secretmanager "cloud.google.com/go/secretmanager/apiv1"
	"cloud.google.com/go/secretmanager/apiv1/secretmanagerpb"
)

func GetSecretFromGCP(secretName string) string {
	ctx := context.Background()

	client, err := secretmanager.NewClient(ctx)
	if err != nil {
		log.Fatalf("failed to create secretmanager client: %v", err)
	}
	defer client.Close()

	req := &secretmanagerpb.AccessSecretVersionRequest{
		Name: secretName,
	}

	result, err := client.AccessSecretVersion(ctx, req)
	if err != nil {
		log.Fatalf("failed to access secret version: %v", err)
	}

	return string(result.Payload.Data)
}


================================

FILE: ./services/clipboard.go
================================

package services

import (
	"bytes"
	"encoding/base64"
	"fmt"
	"image"
	"image/png"
	"os"
	"os/exec"
	"path/filepath"
	"time"

	"golang.design/x/clipboard"
)

func saveClipboardImageAsPng() (string, error) {
	// Construct the expected file path with current timestamp
	homeDir, err := os.UserHomeDir()
	if err != nil {
		return "", err
	}
	fileName := "in_" + time.Now().Format("20060102150405") + ".png"
	filePath := filepath.Join(homeDir, "vision", fileName)
	// Create the directory if it doesn't exist
	err = os.MkdirAll(filepath.Dir(filePath), 0755)
	if err != nil {
		return "", err
	}
	// Construct the osascript command using the file path
	cmdStr := "write (the clipboard as class PNGf) to (open for access (POSIX file \"" + filePath + "\") with write permission)"

	cmd := exec.Command("osascript", "-e", cmdStr)
	// Execute the command
	err = cmd.Run()
	if err != nil {
		return "", err
	}
	return filePath, nil
}

// getImageFromClipboard attempts to read an image from the clipboard
func GetImageFromClipboard() (image.Image, error) {
	// This is platform-specific and might not work on all systems

	// Initialize the clipboard package
	err := clipboard.Init()
	if err != nil {
		panic(fmt.Sprintf("Failed to initialize clipboard: %v", err))
	}

	err = clipboard.Init()
	if err != nil {
		panic(fmt.Sprintf("Failed to initialize clipboard: %v", err))
		// Handle the error appropriately
	}

	// Read image from clipboard
	imgBytes := clipboard.Read(clipboard.FmtImage)

	if len(imgBytes) == 0 {
		panic("Empty image data")
	}

	// If you need the data as an image.Image type for processing
	img, format, err := image.Decode(bytes.NewReader(imgBytes))
	if err != nil {
		panic(fmt.Sprintf("Failed to decode image: %v", err))
	}
	fmt.Printf("Got image from clipboard in format: %s\n", format)

	return img, nil
}

// imageToBase64 converts an image to a base64-encoded string
func ImageToBase64(img image.Image) (string, error) {
	var buf bytes.Buffer

	// Encode image to PNG
	err := png.Encode(&buf, img)
	if err != nil {
		return "", err
	}

	// Encode PNG bytes to base64
	return base64.StdEncoding.EncodeToString(buf.Bytes()), nil
}


================================

FILE: ./services/extract_code.go
================================

package services

import (
	"regexp"
	"strings"
)

func ExtractCodeBlocks(markdown string) []string {
	// Regex to match code blocks (```...```)
	// This handles both with and without language specifiers
	re := regexp.MustCompile("(?s)```(?:\\w*\\n|\\n)(.*?)```")

	matches := re.FindAllStringSubmatch(markdown, -1)

	var codeBlocks []string
	for _, match := range matches {
		if len(match) >= 2 {
			// Trim any leading/trailing whitespace
			code := strings.TrimSpace(match[1])
			codeBlocks = append(codeBlocks, code)
		}
	}

	return codeBlocks
}


================================

FILE: ./services/pdf.go
================================

package services

import (
	"encoding/base64"
	"fmt"
	"os"
	"path/filepath"
)

func ReadPDFAsBase64(filePath string) (string, error) {
	// Ensure the file exists
	if _, err := os.Stat(filePath); os.IsNotExist(err) {
		return "", fmt.Errorf("file does not exist: %s", filePath)
	}

	// Check if it's a PDF file (basic check by extension)
	if filepath.Ext(filePath) != ".pdf" {
		return "", fmt.Errorf("file is not a PDF: %s", filePath)
	}

	// Read the file
	fileBytes, err := os.ReadFile(filePath)
	if err != nil {
		return "", fmt.Errorf("error reading file: %v", err)
	}

	// Convert to base64
	base64String := base64.StdEncoding.EncodeToString(fileBytes)

	return base64String, nil
}


================================

FILE: ./services/query.go
================================

package services

import (
	"bufio"
	"fmt"
	"io"
	"log"
	"net/http"
	"owl/data"
	"owl/logger"
	"owl/models"
)

func AwaitedQuery(prompt string, model models.Model, historyRepository data.HistoryRepository, historyCount int, context *data.Context, image bool, pdf string) {
	history, err := historyRepository.GetHistoryByContextId(context.Id, historyCount)
	if err != nil {
		log.Println("error while fetching history for context", err)
	}

	req := model.CreateRequest(context, prompt, false, history, image, pdf)

	client := &http.Client{}
	resp, err := client.Do(req)
	if err != nil {
		panic(fmt.Errorf("failed to execute request: %v", err))
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		println(fmt.Sprintf("\nresp: %v", resp))
		println(fmt.Sprintf("\n\body: %v\n\n", resp.Body))
		bytes, err := io.ReadAll(resp.Body)
		if err != nil {
			log.Fatal(err)
		}

		fmt.Println(string(bytes))
		println(fmt.Sprintf("\nerr: %v", err))

		panic(fmt.Errorf("received non-OK response status: %d", resp.StatusCode))
	}

	logger.Debug.Printf("statusCode: %s", resp.StatusCode)
	bodyBytes, err := io.ReadAll(resp.Body)
	if err != nil {
		logger.Debug.Println(err)
		// Handle error, maybe return or log
		println(fmt.Sprintf("Error reading response body: %v\n", err))
	} // Close the response body when done
	defer resp.Body.Close()

	logger.Debug.Println("Received a response without streaming")
	logger.Debug.Printf("bodyBytes %s", string(bodyBytes))
	model.HandleBodyBytes(bodyBytes)
	//TODO: Handle token use
}

func StreamedQuery(prompt string, model models.Model, historyRepository data.HistoryRepository, historyCount int, context *data.Context, image bool, pdf string) {
	history, err := historyRepository.GetHistoryByContextId(context.Id, historyCount)

	if err != nil {
		panic(fmt.Sprintf("Could not fetch history %s", err))
	}

	req := model.CreateRequest(context, prompt, true, history, image, pdf)

	client := &http.Client{}
	resp, err := client.Do(req)
	if err != nil {
		panic(fmt.Errorf("Failed to execute request: %v", err))
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		if err != nil {
			panic("Failed to read response body on non-OK status")
		}

		bytes, err := io.ReadAll(resp.Body)
		println("bytes", string(bytes), err)

		panic(fmt.Errorf("received non-OK response status: %d", resp.StatusCode))
	}

	reader := bufio.NewReader(resp.Body)
	finished := false
	for !finished {
		line, err := reader.ReadBytes('\n')
		if err != nil {
			fmt.Println("failed to read bytes from stream response")
			finished = true
			continue
		}

		model.HandleStreamedLine(line)
	}
}


================================

FILE: ./test_helpers/mocks.go
================================

package test_helpers

import (
	"owl/data"
	"owl/models"
)

// MockModel implements the models.Model interface for testing
type MockModel struct {
	ResponseText string
	ShouldError  bool
	ErrorText    string
}

func (m *MockModel) Query(prompt string, user data.User, historyCount int, context *data.Context, useImage bool, pdfPath string) (string, error) {
	if m.ShouldError {
		return "", fmt.Errorf(m.ErrorText)
	}
	return m.ResponseText, nil
}

func (m *MockModel) StreamQuery(prompt string, user data.User, historyCount int, context *data.Context, useImage bool, pdfPath string) error {
	if m.ShouldError {
		return fmt.Errorf(m.ErrorText)
	}
	return nil
}

// MockResponseHandler for testing
type MockResponseHandler struct {
	ReceivedContent []string
	ShouldError     bool
}

func (h *MockResponseHandler) HandleResponse(content string) error {
	if h.ShouldError {
		return fmt.Errorf("mock handler error")
	}
	h.ReceivedContent = append(h.ReceivedContent, content)
	return nil
}

// MockUser for testing database operations
type MockUser struct {
	Name     *string
	Contexts map[string]*data.Context
	History  map[int][]*data.History
}

func (u *MockUser) GetContextByName(name string) (*data.Context, error) {
	if context, exists := u.Contexts[name]; exists {
		return context, nil
	}
	return nil, fmt.Errorf("context not found: %s", name)
}

func (u *MockUser) GetHistoryByContextId(contextId int, count int) ([]*data.History, error) {
	if history, exists := u.History[contextId]; exists {
		if len(history) < count {
			return history, nil
		}
		return history[:count], nil
	}
	return []*data.History{}, nil
}


================================

FILE: ./tui/chat_histoy_view.go
================================

package tui

import (
	"fmt"
	"owl/data"
	"owl/services"
	"strings"

	"github.com/atotto/clipboard"
	"github.com/charmbracelet/bubbles/viewport"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/glamour"
)

type historyViewMode int

const (
	historyCompactMode historyViewMode = iota
	historyExpandedMode
	historyCodeViewMode
)

type chatHistoryViewModel struct {
	shared      *sharedState
	history     []data.History
	viewport    viewport.Model
	cursor      int
	mode        historyViewMode
	expandedIdx int // Which message is expanded (-1 = none)
	ready       bool
	loading     bool
	width       int
	height      int
	err         error
}

func newChatHistoryViewModel(shared *sharedState) *chatHistoryViewModel {
	vp := viewport.New(shared.width, shared.height-5)
	vp.YPosition = 0

	return &chatHistoryViewModel{
		shared:      shared,
		viewport:    vp,
		cursor:      0,
		mode:        historyCompactMode,
		expandedIdx: -1,
		loading:     true,
		width:       shared.width,
		height:      shared.height,
	}
}

func (m *chatHistoryViewModel) Init() tea.Cmd {
	return m.loadHistory()
}

func (m *chatHistoryViewModel) loadHistory() tea.Cmd {
	return func() tea.Msg {
		history, err := m.shared.config.Repository.GetHistoryByContextId(
			m.shared.selectedCtx.Id,
			1000, // Load all history for browsing
		)

		if err != nil {
			return errorMsg{err}
		}
		return historyLoadedMsg(history)
	}
}

func (m *chatHistoryViewModel) scrollToSelection() {
	if len(m.history) == 0 {
		return
	}

	// Each message in compact mode takes 3 lines (prompt + response + blank)
	linesPerMessage := 3

	// Calculate the line position of the current cursor
	cursorLine := m.cursor * linesPerMessage

	// Calculate visible range
	viewportTop := m.viewport.YOffset
	viewportBottom := viewportTop + m.viewport.Height

	// If cursor is above viewport, scroll up
	if cursorLine < viewportTop {
		m.viewport.SetYOffset(cursorLine)
	}

	// If cursor is below viewport, scroll down
	// We want the cursor item to be visible, so check if cursor + item height is visible
	cursorBottom := cursorLine + linesPerMessage
	if cursorBottom > viewportBottom {
		// Scroll so the cursor item is at the bottom of the viewport
		newOffset := cursorBottom - m.viewport.Height
		if newOffset < 0 {
			newOffset = 0
		}
		m.viewport.SetYOffset(newOffset)
	}
}

func (m *chatHistoryViewModel) Update(msg tea.Msg) (tea.Model, tea.Cmd) {
	var vpCmd tea.Cmd

	switch msg := msg.(type) {
	case tea.KeyMsg:
		if m.loading {
			return m, nil
		}

		// Code view mode
		if m.mode == historyCodeViewMode {
			switch msg.String() {
			case "esc", "q", "c":
				m.mode = historyCompactMode
				m.updateContent()
				return m, nil
			case "y":
				// Copy code to clipboard
				if m.expandedIdx >= 0 && m.expandedIdx < len(m.history) {
					code := services.ExtractCodeBlocks(m.history[m.expandedIdx].Response)
					allCode := strings.Join(code, "\n\n")
					clipboard.WriteAll(allCode)
				}
				return m, nil
			}
			// Allow scrolling in code view
			m.viewport, vpCmd = m.viewport.Update(msg)
			return m, vpCmd
		}

		// Expanded view mode
		if m.mode == historyExpandedMode {
			switch msg.String() {
			case "esc", "q":
				m.mode = historyCompactMode
				m.expandedIdx = -1
				m.updateContent()
				m.scrollToSelection() // Scroll to cursor when returning to compact
				return m, nil
			case "c":
				// View code
				if m.expandedIdx >= 0 && m.expandedIdx < len(m.history) {
					m.mode = historyCodeViewMode
					m.updateContent()
				}
				return m, nil
			case "y":
				// Copy full response
				if m.expandedIdx >= 0 && m.expandedIdx < len(m.history) {
					clipboard.WriteAll(m.history[m.expandedIdx].Response)
				}
				return m, nil
			}
			// Allow scrolling in expanded view
			m.viewport, vpCmd = m.viewport.Update(msg)
			return m, vpCmd
		}

		// Compact mode navigation
		switch msg.String() {
		case "ctrl+c":
			return m, tea.Quit

		case "esc", "q":
			// Return to chat view
			chatView := newChatViewModel(m.shared)
			return chatView, tea.Sequence(
				chatView.Init(),
				func() tea.Msg {
					return tea.WindowSizeMsg{
						Width:  m.shared.width,
						Height: m.shared.height,
					}
				},
			)

		case "up", "k":
			if m.cursor > 0 {
				m.cursor--
				m.updateContent()
				m.scrollToSelection() //  Add this
			}

		case "down", "j":
			if m.cursor < len(m.history)-1 {
				m.cursor++
				m.updateContent()
				m.scrollToSelection() //  Add this
			}

		case "g":
			// Go to top
			m.cursor = 0
			m.updateContent()
			m.scrollToSelection() //  Add this

		case "G":
			// Go to bottom
			if len(m.history) > 0 {
				m.cursor = len(m.history) - 1
			}
			m.updateContent()
			m.scrollToSelection() //  Add this

		case "enter", "e":
			// Expand selected message
			m.expandedIdx = m.cursor
			m.mode = historyExpandedMode
			m.updateContent()

		case "c":
			// View code for selected message
			if m.cursor < len(m.history) {
				code := services.ExtractCodeBlocks(m.history[m.cursor].Response)
				if len(code) > 0 {
					m.expandedIdx = m.cursor
					m.mode = historyCodeViewMode
					m.updateContent()
				}
			}

		case "y":
			// Copy response of selected message
			if m.cursor < len(m.history) {
				clipboard.WriteAll(m.history[m.cursor].Response)
			}

		case "r":
			// Refresh
			m.loading = true
			return m, m.loadHistory()
		}

	case historyLoadedMsg:
		m.history = []data.History(msg)
		m.loading = false
		m.updateContent()
		m.scrollToSelection()

	case errorMsg:
		m.err = msg.err
		m.loading = false

	case tea.WindowSizeMsg:
		m.width = msg.Width
		m.height = msg.Height

		if !m.ready {
			m.viewport = viewport.New(msg.Width, msg.Height-5)
			m.viewport.YPosition = 0
			m.ready = true
		} else {
			m.viewport.Width = msg.Width
			m.viewport.Height = msg.Height - 5
		}
		m.updateContent()
		m.scrollToSelection()
	}

	return m, vpCmd
}

func (m *chatHistoryViewModel) updateContent() {
	if len(m.history) == 0 {
		m.viewport.SetContent(dimStyle.Render("No history yet"))
		return
	}

	switch m.mode {
	case historyCompactMode:
		m.viewport.SetContent(m.renderCompactMode())
	case historyExpandedMode:
		m.viewport.SetContent(m.renderExpandedMode())
	case historyCodeViewMode:
		m.viewport.SetContent(m.renderCodeViewMode())
	}
}

func (m *chatHistoryViewModel) renderCompactMode() string {
	var b strings.Builder

	for i, h := range m.history {
		cursor := "  "
		style := itemStyle

		if i == m.cursor {
			cursor = " "
			style = selectedItemStyle
		}

		// Check if message contains code
		codeIndicator := ""
		code := services.ExtractCodeBlocks(h.Response)
		if len(code) > 0 {
			codeIndicator = dimStyle.Render(" ")
		}

		// Truncate prompt to 1 line
		prompt := h.Prompt
		if len(prompt) > m.width-10 {
			prompt = prompt[:m.width-13] + "..."
		}
		prompt = strings.ReplaceAll(prompt, "\n", " ")

		// Truncate response to 2 lines
		response := h.Response
		lines := strings.Split(response, "\n")
		if len(lines) > 2 {
			response = strings.Join(lines[:2], " ") + "..."
		} else {
			response = strings.ReplaceAll(response, "\n", " ")
		}
		if len(response) > m.width-10 {
			response = response[:m.width-13] + "..."
		}

		// Format: cursor [#] prompt | response [code]
		line := fmt.Sprintf("%s[%d]%s %s",
			cursor,
			i+1,
			codeIndicator,
			dimStyle.Render("Q:"))
		b.WriteString(style.Render(line))
		b.WriteString(" ")
		b.WriteString(style.Render(prompt))
		b.WriteString("\n")

		b.WriteString(style.Render("    " + dimStyle.Render("A: ") + response))
		b.WriteString("\n\n")
	}

	return b.String()
}

func (m *chatHistoryViewModel) renderExpandedMode() string {
	if m.expandedIdx < 0 || m.expandedIdx >= len(m.history) {
		return "Invalid message index"
	}

	h := m.history[m.expandedIdx]
	var b strings.Builder

	// Header
	b.WriteString(headerStyle.Render(fmt.Sprintf("Message %d of %d", m.expandedIdx+1, len(m.history))))
	b.WriteString("\n\n")

	// Check if has code
	code := services.ExtractCodeBlocks(h.Response)
	if len(code) > 0 {
		b.WriteString(dimStyle.Render(fmt.Sprintf(" Contains %d code block(s) - press 'c' to view", len(code))))
		b.WriteString("\n\n")
	}

	// Prompt
	b.WriteString(userPromptStyle.Render("Question:"))
	b.WriteString("\n")
	b.WriteString(h.Prompt)
	b.WriteString("\n\n")

	// Response
	b.WriteString(aiResponseStyle.Render("Answer:"))
	b.WriteString("\n")
	rendered, err := glamour.Render(h.Response, "dark")
	if err != nil {
		rendered = h.Response
	}
	b.WriteString(rendered)

	return b.String()
}

func (m *chatHistoryViewModel) renderCodeViewMode() string {
	if m.expandedIdx < 0 || m.expandedIdx >= len(m.history) {
		return "Invalid message index"
	}

	h := m.history[m.expandedIdx]
	code := services.ExtractCodeBlocks(h.Response)

	var b strings.Builder

	// Header
	b.WriteString(headerStyle.Render(fmt.Sprintf("Code Blocks - Message %d", m.expandedIdx+1)))
	b.WriteString("\n\n")

	if len(code) == 0 {
		b.WriteString(dimStyle.Render("No code blocks found"))
	} else {
		for i, block := range code {
			b.WriteString(dimStyle.Render(fmt.Sprintf(" Block %d of %d ", i+1, len(code))))
			b.WriteString("\n")
			b.WriteString(block)
			b.WriteString("\n\n")
		}
	}

	return b.String()
}

func (m *chatHistoryViewModel) View() string {
	if m.loading {
		return loadingStyle.Render("Loading history...")
	}

	if m.err != nil {
		return errorStyle.Render(fmt.Sprintf("Error: %v\n\nPress ESC to go back", m.err))
	}

	// Build help text based on mode
	var help string
	switch m.mode {
	case historyCompactMode:
		help = "//j/k navigate  enter/e expand  c code  y copy  g top  G bottom  r refresh  esc/q back"
	case historyExpandedMode:
		help = "c view code  y copy  esc/q back"
	case historyCodeViewMode:
		help = "y copy code  esc/q back"
	}

	modeLabel := ""
	switch m.mode {
	case historyCompactMode:
		modeLabel = fmt.Sprintf("Compact (%d messages)", len(m.history))
	case historyExpandedMode:
		modeLabel = fmt.Sprintf("Message %d", m.expandedIdx+1)
	case historyCodeViewMode:
		modeLabel = fmt.Sprintf("Code View - Message %d", m.expandedIdx+1)
	}

	return fmt.Sprintf(
		"%s %s\n\n%s\n\n%s",
		headerStyle.Render(fmt.Sprintf(" History: %s", m.shared.selectedCtx.Name)),
		dimStyle.Render(fmt.Sprintf("[%s]", modeLabel)),
		m.viewport.View(),
		helpStyle.Render(help),
	)
}


================================

FILE: ./tui/chat_view.go
================================

package tui

import (
	"fmt"
	"owl/data"
	"owl/logger"
	"owl/services"
	"strings"

	"github.com/atotto/clipboard"
	"github.com/charmbracelet/bubbles/textarea"
	"github.com/charmbracelet/bubbles/viewport"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/glamour"
	claude_model "owl/models/claude"
	grok_model "owl/models/grok"
	openai_4o_model "owl/models/open-ai-4o"
)

type chatMode int

const (
	chatNormalMode chatMode = iota
	chatModelSelectMode
)

type chatViewModel struct {
	shared          *sharedState
	history         []data.History
	textarea        textarea.Model
	viewport        viewport.Model
	loading         bool
	ready           bool
	sending         bool
	width           int
	height          int
	err             error
	historyLoaded   bool
	currentResponse string
	currentPrompt   string
	responseChan    chan string
	doneChan        chan struct{}
	mode            chatMode

	// Model selection
	availableModels  []string
	selectedModelIdx int
	modelCursor      int
}

type historyLoadedMsg []data.History
type messageReceivedMsg string
type messageDoneMsg struct {
	prompt   string
	response string
}

func newChatViewModel(shared *sharedState) *chatViewModel {
	ta := textarea.New()
	ta.Placeholder = "Type your message..."
	ta.Focus()
	ta.CharLimit = 5000
	ta.SetWidth(shared.width - 4)
	ta.SetHeight(3)

	vp := viewport.New(shared.width, shared.height-10)
	vp.YPosition = 0

	// TODO: Get this list from config or a model provider
	availableModels := []string{
		"claude",
		"grok",
		"4o",
		"opus",
		"sonnet",
	}

	return &chatViewModel{
		shared:           shared,
		textarea:         ta,
		viewport:         vp,
		loading:          true,
		ready:            false,
		width:            shared.width,
		height:           shared.height,
		availableModels:  availableModels,
		selectedModelIdx: 0, // Default to first model
		mode:             chatNormalMode,
	}
}

func (m *chatViewModel) Init() tea.Cmd {
	logger.Debug.Printf("init")

	return tea.Batch(
		textarea.Blink,
		m.loadHistory(),
	)
}

func (m *chatViewModel) loadHistory() tea.Cmd {
	return func() tea.Msg {
		history, err := m.shared.config.Repository.GetHistoryByContextId(
			m.shared.selectedCtx.Id,
			m.shared.config.HistoryCount,
		)

		if err != nil {
			return errorMsg{err}
		}
		return historyLoadedMsg(history)
	}
}

type chatChunkMsg struct {
	text         string
	responseChan chan string
	doneChan     chan struct{}
	prompt       string
}

type chatCompleteMsg struct {
	prompt   string
	response string
}

type chatErrorMsg struct {
	err error
}

func (m *chatViewModel) sendMessage(prompt string) tea.Cmd {
	return func() tea.Msg {
		// Create channels
		responseChan := make(chan string, 100)
		doneChan := make(chan struct{})

		handler := &tuiResponseHandler{
			responseChan: responseChan,
			doneChan:     doneChan,
			fullResponse: "",
			Repository:   m.shared.config.Repository,
		}

		model := m.shared.config.Model

		logger.Debug.Printf("MODEL SELECTION: %s", m.availableModels[m.selectedModelIdx])
		switch m.availableModels[m.selectedModelIdx] {
		case "grok":
			logger.Debug.Println("setting grok as model")
			model = &grok_model.GrokModel{ResponseHandler: handler}
		case "4o":
			model = &openai_4o_model.OpenAi4oModel{ResponseHandler: handler}
		case "claude":
			model = &claude_model.ClaudeModel{ResponseHandler: handler, UseThinking: true, StreamThought: true, OutputThought: false}
		case "opus":
			model = &claude_model.ClaudeModel{ResponseHandler: handler, UseThinking: true, StreamThought: true, OutputThought: false, ModelVersion: "opus"}
		case "sonnet":
			model = &claude_model.ClaudeModel{ResponseHandler: handler, UseThinking: true, StreamThought: true, OutputThought: false, ModelVersion: "sonnet"}
		default:
			model = &claude_model.ClaudeModel{ResponseHandler: handler, UseThinking: true, StreamThought: true, OutputThought: false}
		}

		m.shared.config.Model = model

		logger.Debug.Printf("MODEL SELECTION after: %s", model)

		model.SetResponseHandler(handler)

		// Start query in goroutine
		go func() {
			services.StreamedQuery(
				prompt,
				model,
				m.shared.config.Repository,
				m.shared.config.HistoryCount,
				m.shared.selectedCtx,
				false,
				"",
			)
		}()

		// Execute the wait function immediately
		waitCmd := waitForChatActivity(responseChan, doneChan, prompt)
		return waitCmd()
	}
}

func waitForChatActivity(responseChan chan string, doneChan chan struct{},
	prompt string) tea.Cmd {

	logger.Debug.Println("waitForChatActivity started")

	return func() tea.Msg {
		logger.Debug.Println("inside the function")
		logger.Debug.Printf("responseChan %s", responseChan)
		select {
		case text, ok := <-responseChan:
			logger.Debug.Printf("responseChan: %v: %s", ok, text)
			if !ok {
				// Channel closed, streaming done
				return chatCompleteMsg{prompt: prompt}
			}
			return chatChunkMsg{
				text:         text,
				responseChan: responseChan,
				doneChan:     doneChan,
				prompt:       prompt,
			}
		case <-doneChan:
			logger.Debug.Printf("doneChan from waitForChatActivity")
			return chatCompleteMsg{prompt: prompt}
		}
	}
}

func (m *chatViewModel) Update(msg tea.Msg) (tea.Model, tea.Cmd) {
	var (
		tiCmd tea.Cmd
		vpCmd tea.Cmd
	)

	shouldUpdateViewport := false

	switch msg := msg.(type) {
	case chatChunkMsg:
		// Update UI with new text chunk
		m.currentResponse += msg.text
		m.updateViewportContent()
		// Important: return another command to keep listening
		return m, waitForChatActivity(msg.responseChan, msg.doneChan, msg.prompt)

	case chatCompleteMsg:
		logger.Debug.Println("got chatCompleteMsg")
		// Streaming complete, finalize UI
		m.sending = false
		m.loading = false
		// Reload history to show the new message
		return m, m.loadHistory()

	case chatErrorMsg:
		// Handle error
		m.err = msg.err
		m.loading = false
		m.sending = false

	case tea.KeyMsg:
		if m.sending {
			return m, nil
		}

		// Handle model selection mode
		if m.mode == chatModelSelectMode {
			switch msg.String() {
			case "esc", "q":
				m.mode = chatNormalMode
				m.modelCursor = m.selectedModelIdx
				return m, nil

			case "up", "k":
				if m.modelCursor > 0 {
					m.modelCursor--
				}

			case "down", "j":
				if m.modelCursor < len(m.availableModels)-1 {
					m.modelCursor++
				}

			case "enter":
				m.selectedModelIdx = m.modelCursor
				m.mode = chatNormalMode
				return m, nil

			}
			return m, nil
		}

		// Normal mode key handling
		switch msg.String() {

		case "ctrl+a":
			// Open history detail view
			logger.Debug.Println("tried to launch history view")
			historyView := newChatHistoryViewModel(m.shared)
			return historyView, tea.Sequence(
				historyView.Init(),
				func() tea.Msg {
					return tea.WindowSizeMsg{
						Width:  m.shared.width,
						Height: m.shared.height,
					}
				},
			)

		case "ctrl+c":
			return m, tea.Quit

		case "esc":
			// Return to list view
			listView := newListViewModel(m.shared.config)
			return listView, tea.Sequence(
				listView.Init(),
				func() tea.Msg {
					return tea.WindowSizeMsg{
						Width:  m.shared.width,
						Height: m.shared.height,
					}
				},
			)

		case "ctrl+s":
			// Copy command to clipboard
			cmd := fmt.Sprintf("owl --context_name %s --prompt \"\"",
				m.shared.selectedCtx.Name)
			clipboard.WriteAll(cmd)

		case "ctrl+g":
			// Open model selector
			m.mode = chatModelSelectMode
			m.modelCursor = m.selectedModelIdx

		case "ctrl+w":
			// Send message
			if !m.sending && m.textarea.Value() != "" {
				m.sending = true
				prompt := m.textarea.Value()
				m.currentPrompt = prompt
				m.currentResponse = ""
				m.textarea.Reset()
				return m, m.sendMessage(prompt)
			}
			// Allow viewport scrolling ONLY on ctrl combinations
		case "ctrl+u", "ctrl+d", "ctrl+b", "ctrl+t", "ctrl+f", "pgup", "pgdown":
			shouldUpdateViewport = true

			// Regular letters should NOT scroll the viewport
			// They'll be handled by the textarea
		default:
			// Don't update viewport, only textarea
		}

	case historyLoadedMsg:
		logger.Debug.Printf("historyLoaded msg handled")
		m.history = []data.History(msg)
		m.loading = false
		m.historyLoaded = true
		m.updateViewportContent()

	case messageDoneMsg:
		m.sending = false
		// Reload history
		return m, m.loadHistory()

	case errorMsg:
		m.err = msg.err
		m.loading = false
		m.sending = false

	case tea.WindowSizeMsg:
		m.width = msg.Width
		m.height = msg.Height

		logger.Debug.Printf("windowSizeMsg")
		if !m.ready {
			logger.Debug.Printf("windowSizeMsg not ready")
			m.viewport = viewport.New(msg.Width, msg.Height-10)
			m.viewport.YPosition = 0
			m.ready = true
			m.updateViewportContent()
		} else {
			m.viewport.Width = msg.Width
			m.viewport.Height = msg.Height - 10
		}

		m.textarea.SetWidth(msg.Width - 4)
	}

	m.textarea, tiCmd = m.textarea.Update(msg)

	if shouldUpdateViewport {
		m.viewport, vpCmd = m.viewport.Update(msg)
	}

	return m, tea.Batch(tiCmd, vpCmd)
}

func (m *chatViewModel) updateViewportContent() {
	logger.Debug.Printf("historyLoaded %s", m.historyLoaded)
	if !m.historyLoaded {
		return
	}
	logger.Debug.Printf("passed guard")

	var b strings.Builder

	logger.Debug.Printf("history count %d", len(m.history))
	for i, h := range m.history {
		logger.Debug.Printf("add history %d", i)
		// Render user prompt
		b.WriteString(userPromptStyle.Render(fmt.Sprintf("You: %s", h.Prompt)))
		b.WriteString("\n\n")

		// Render AI response with glamour
		rendered, err := glamour.Render(h.Response, "dark")
		if err != nil {
			rendered = h.Response
		}
		b.WriteString(aiResponseStyle.Render(rendered))
		b.WriteString("\n")
		b.WriteString(strings.Repeat("", m.width))
		b.WriteString("\n\n")
	}

	// Show current response if streaming
	if m.sending && m.currentResponse != "" {
		b.WriteString(userPromptStyle.Render(fmt.Sprintf("You: %s", m.currentPrompt)))
		b.WriteString("\n\n")

		rendered, err := glamour.Render(m.currentResponse, "dark")
		if err != nil {
			rendered = m.currentResponse
		}
		b.WriteString(aiResponseStyle.Render(rendered))
		b.WriteString("\n")
	}

	m.viewport.SetContent(b.String())
	if m.viewport.Height > 0 && m.viewport.Width > 0 {
		m.viewport.GotoBottom()
	}
}

func (m *chatViewModel) View() string {
	if m.loading || !m.historyLoaded {
		return loadingStyle.Render("Loading conversation...")
	}

	if m.err != nil {
		return errorStyle.Render(fmt.Sprintf("Error: %v\n\nPress ESC to go back", m.err))
	}

	// Show model selector
	if m.mode == chatModelSelectMode {
		return m.renderModelSelector()
	}

	// Normal chat view
	status := ""
	if m.sending {
		status = sendingStyle.Render(" Sending...")
	}

	currentModel := m.availableModels[m.selectedModelIdx]
	modelInfo := dimStyle.Render(fmt.Sprintf(" [%s]", currentModel))

	return fmt.Sprintf(
		"%s%s\n\n%s\n\n%s\n%s%s",
		headerStyle.Render(fmt.Sprintf(" %s", m.shared.selectedCtx.Name)),
		modelInfo,
		m.viewport.View(),
		m.textarea.View(),
		helpStyle.Render("ctrl+w send  ctrl+m model  ctrl+h history  ctrl+s copy cmd  esc back  ctrl+c quit"),
		status,
	)
}

func (m *chatViewModel) renderModelSelector() string {
	var b strings.Builder

	b.WriteString(headerStyle.Render("Select Model"))
	b.WriteString("\n\n")

	for i, model := range m.availableModels {
		cursor := " "
		style := itemStyle

		if i == m.modelCursor {
			cursor = ">"
			style = selectedItemStyle
		}

		// Highlight the currently selected model
		modelName := model
		if i == m.selectedModelIdx {
			modelName += " "
		}

		line := fmt.Sprintf("%s %s", cursor, modelName)
		b.WriteString(style.Render(line))
		b.WriteString("\n")
	}

	b.WriteString("\n")
	b.WriteString(helpStyle.Render("/k up  /j down  enter select  esc/q cancel"))

	return b.String()
}

// TUI-specific response handler
type tuiResponseHandler struct {
	responseChan chan string
	doneChan     chan struct{}
	fullResponse string
	Repository   data.HistoryRepository
}

func (h *tuiResponseHandler) RecievedText(text string, color *string) {
	h.fullResponse += text
	h.responseChan <- text
}

func (h *tuiResponseHandler) FinalText(contextId int64, prompt string, response string) {
	h.fullResponse = response

	// Signal done BEFORE closing responseChan
	logger.Debug.Println("Final text in tui response channel")
	logger.Debug.Println("closing doneChan and responseChan")
	close(h.doneChan)
	close(h.responseChan)

	history := data.History{
		ContextId:    contextId,
		Prompt:       prompt,
		Response:     response,
		Abbreviation: "",
		TokenCount:   0,
	}

	_, err := h.Repository.InsertHistory(history)
	if err != nil {
		println(fmt.Sprintf("Error while trying to save history: %s", err))
	}

	code := services.ExtractCodeBlocks(response)
	allCode := strings.Join(code, "\n\n")

	// Copy to clipboard
	err = clipboard.WriteAll(allCode)
	if err != nil {
		fmt.Printf("Error copying to clipboard: %v\n", err)
	}
}

// package tui
//
// import (
// 	"fmt"
// 	"owl/data"
// 	"owl/logger"
// 	"owl/services"
// 	"strings"
//
// 	"github.com/atotto/clipboard"
// 	"github.com/charmbracelet/bubbles/textarea"
// 	"github.com/charmbracelet/bubbles/viewport"
// 	tea "github.com/charmbracelet/bubbletea"
// 	"github.com/charmbracelet/glamour"
// )
//
// type chatViewModel struct {
// 	shared          *sharedState
// 	history         []data.History
// 	textarea        textarea.Model
// 	viewport        viewport.Model
// 	loading         bool
// 	ready           bool
// 	sending         bool
// 	width           int
// 	height          int
// 	err             error
// 	historyLoaded   bool
// 	currentResponse string
// 	currentPrompt   string
// 	responseChan    chan string
// 	doneChan        chan struct{}
// }
//
// type historyLoadedMsg []data.History
// type messageReceivedMsg string
// type messageDoneMsg struct {
// 	prompt   string
// 	response string
// }
//
// func newChatViewModel(shared *sharedState) *chatViewModel {
// 	ta := textarea.New()
// 	ta.Placeholder = "Type your message..."
// 	ta.Focus()
// 	ta.CharLimit = 5000
// 	ta.SetWidth(shared.width - 4)
// 	ta.SetHeight(3)
//
// 	vp := viewport.New(shared.width, shared.height-10)
// 	vp.YPosition = 0
//
// 	return &chatViewModel{
// 		shared:   shared,
// 		textarea: ta,
// 		viewport: vp,
// 		loading:  true,
// 		ready:    false,
// 		width:    shared.width,
// 		height:   shared.height,
// 	}
// }
//
// func (m *chatViewModel) Init() tea.Cmd {
//
// 	logger.Debug.Printf("init")
//
// 	return tea.Batch(
// 		textarea.Blink,
// 		m.loadHistory(),
// 	)
// }
//
// func (m *chatViewModel) loadHistory() tea.Cmd {
// 	logger.Debug.Println("loadHistory")
// 	return func() tea.Msg {
// 		history, err := m.shared.config.Repository.GetHistoryByContextId(
// 			m.shared.selectedCtx.Id,
// 			m.shared.config.HistoryCount,
// 		)
// 		// debugLog.Printf("history %s", history)
//
// 		if err != nil {
// 			return errorMsg{err}
// 		}
// 		logger.Debug.Println("returning historyLoadedMsg")
// 		return historyLoadedMsg(history)
// 	}
// }
//
// type chatChunkMsg struct {
// 	text         string
// 	responseChan chan string
// 	doneChan     chan struct{}
// 	prompt       string
// }
//
// type chatCompleteMsg struct {
// 	prompt string
// }
//
// type chatErrorMsg struct {
// 	err error
// }
//
// func (m *chatViewModel) sendMessage(prompt string) tea.Cmd {
// 	return func() tea.Msg {
// 		// Create channels
// 		responseChan := make(chan string, 100)
// 		doneChan := make(chan struct{})
//
// 		handler := &tuiResponseHandler{
// 			responseChan: responseChan,
// 			doneChan:     doneChan,
// 			fullResponse: "",
// 			Repository:   m.shared.config.Repository,
// 		}
//
// 		model := m.shared.config.Model
// 		model.SetResponseHandler(handler)
//
// 		// Start query in goroutine
// 		go func() {
// 			services.StreamedQuery(
// 				prompt,
// 				model,
// 				m.shared.config.Repository,
// 				m.shared.config.HistoryCount,
// 				m.shared.selectedCtx,
// 				false,
// 				"",
// 			)
// 		}()
//
// 		// Execute the wait function immediately
// 		waitCmd := waitForChatActivity(responseChan, doneChan, prompt)
// 		return waitCmd() //  Execute the function!
// 	}
// }
//
// func waitForChatActivity(responseChan chan string, doneChan chan struct{},
// 	prompt string) tea.Cmd {
//
// 	logger.Debug.Println("waitForChatActivity started")
//
// 	return func() tea.Msg {
// 		logger.Debug.Println("inside the fuction")
// 		logger.Debug.Printf("responseChan %s", responseChan)
// 		select {
// 		case text, ok := <-responseChan:
// 			logger.Debug.Printf("responseChan: %v: %s", ok, text)
// 			if !ok {
// 				// Channel closed, streaming done
// 				return chatCompleteMsg{prompt: prompt}
// 			}
// 			return chatChunkMsg{
// 				text:         text,
// 				responseChan: responseChan, // Pass channels forward
// 				doneChan:     doneChan,
// 				prompt:       prompt,
// 			}
// 		case <-doneChan:
// 			logger.Debug.Printf("doneChan from waitForChatActivity")
// 			return chatCompleteMsg{prompt: prompt}
// 		}
// 	}
// }
//
// func (m *chatViewModel) Update(msg tea.Msg) (tea.Model, tea.Cmd) {
// 	var (
// 		tiCmd tea.Cmd
// 		vpCmd tea.Cmd
// 	)
//
// 	switch msg := msg.(type) {
// 	case chatChunkMsg:
// 		logger.Debug.Println("got chatChunkMsg")
// 		// Append the chunk to your response
// 		//TODO: update ui with this text
// 		m.currentResponse += msg.text
//
// 		// CRITICAL: Continue listening for more chunks
// 		return m, waitForChatActivity(msg.responseChan, msg.doneChan, msg.prompt)
//
// 	case chatCompleteMsg:
// 		logger.Debug.Println("got chatCompleteMsg")
// 		m.sending = false
// 		return m, m.loadHistory()
//
// 	case chatErrorMsg:
// 		// Handle error
// 		m.err = msg.err
// 		return m, nil
//
// 	case tea.KeyMsg:
// 		if m.sending {
// 			return m, nil
// 		}
//
// 		switch msg.String() {
// 		case "ctrl+c":
// 			return m, tea.Quit
//
// 		case "esc":
// 			// Return to list view
// 			listView := newListViewModel(m.shared.config)
// 			return listView, tea.Sequence(
// 				listView.Init(),
// 				func() tea.Msg {
// 					return tea.WindowSizeMsg{
// 						Width:  m.shared.width,
// 						Height: m.shared.height,
// 					}
// 				},
// 			)
//
// 		case "ctrl+s":
// 			// Copy command to clipboard
// 			cmd := fmt.Sprintf("owl --stream --context_name %s --prompt \"\"",
// 				m.shared.selectedCtx.Name)
// 			clipboard.WriteAll(cmd)
//
// 		case "ctrl+w":
// 			// Send message
// 			if !m.sending && m.textarea.Value() != "" {
// 				m.sending = true
// 				prompt := m.textarea.Value()
// 				m.textarea.Reset()
// 				return m, m.sendMessage(prompt)
// 			}
// 		}
//
// 	case historyLoadedMsg:
// 		logger.Debug.Printf("historyLoaded msg handled")
// 		m.history = []data.History(msg)
// 		// debugLog.Printf("historyLoaded msg handled %s, %s", len(m.history), msg)
// 		m.loading = false
// 		m.historyLoaded = true
// 		m.updateViewportContent()
//
// 	case messageDoneMsg:
// 		m.sending = false
// 		// Reload history
// 		return m, m.loadHistory()
//
// 	case errorMsg:
// 		m.err = msg.err
// 		m.loading = false
// 		m.sending = false
//
// 	case tea.WindowSizeMsg:
// 		m.width = msg.Width
// 		m.height = msg.Height
//
// 		logger.Debug.Printf("windowSizeMsg")
// 		if !m.ready {
// 			logger.Debug.Printf("windowSizeMsg not ready")
// 			m.viewport = viewport.New(msg.Width, msg.Height-10)
// 			m.viewport.YPosition = 0
// 			m.ready = true
// 			m.updateViewportContent()
// 		} else {
// 			m.viewport.Width = msg.Width
// 			m.viewport.Height = msg.Height - 10
// 		}
//
// 		m.textarea.SetWidth(msg.Width - 4)
// 	}
//
// 	m.textarea, tiCmd = m.textarea.Update(msg)
// 	m.viewport, vpCmd = m.viewport.Update(msg)
//
// 	return m, tea.Batch(tiCmd, vpCmd)
// }
//
// func (m *chatViewModel) updateViewportContent() {
//
// 	logger.Debug.Printf("historyLoaded %s", m.historyLoaded)
// 	if !m.historyLoaded {
// 		return
// 	}
// 	logger.Debug.Printf("passed guard")
//
// 	var b strings.Builder
//
// 	logger.Debug.Printf("history count %i", len(m.history))
// 	for i, h := range m.history {
// 		logger.Debug.Printf("add history %i", i)
// 		// Render user prompt
// 		b.WriteString(userPromptStyle.Render(fmt.Sprintf("You: %s", h.Prompt)))
// 		b.WriteString("\n\n")
//
// 		// Render AI response with glamour
// 		rendered, err := glamour.Render(h.Response, "dark")
// 		if err != nil {
// 			rendered = h.Response
// 		}
// 		b.WriteString(aiResponseStyle.Render(rendered))
// 		b.WriteString("\n")
// 		b.WriteString(strings.Repeat("", m.width))
// 		b.WriteString("\n\n")
// 	}
// 	// debugLog.Printf(b.String())
//
// 	m.viewport.SetContent(b.String())
// 	if m.viewport.Height > 0 && m.viewport.Width > 0 {
// 		m.viewport.GotoBottom()
// 	}
// }
//
// func (m *chatViewModel) View() string {
// 	if m.loading || !m.historyLoaded {
// 		return loadingStyle.Render("Loading conversation...")
// 	}
//
// 	if m.err != nil {
// 		return errorStyle.Render(fmt.Sprintf("Error: %v\n\nPress ESC to go back", m.err))
// 	}
//
// 	status := ""
// 	if m.sending {
// 		status = sendingStyle.Render(" Sending...")
// 	}
//
// 	return fmt.Sprintf(
// 		"%s\n\n%s\n\n%s\n%s%s",
// 		headerStyle.Render(fmt.Sprintf(" %s", m.shared.selectedCtx.Name)),
// 		m.viewport.View(),
// 		m.textarea.View(),
// 		helpStyle.Render("ctrl+w send  ctrl+s copy cmd  esc back  ctrl+c quit"),
// 		status,
// 	)
// }
//
// // TUI-specific response handler
// type tuiResponseHandler struct {
// 	responseChan chan string
// 	doneChan     chan struct{}
// 	fullResponse string
// 	Repository   data.HistoryRepository
// }
//
// func (h *tuiResponseHandler) RecievedText(text string, color *string) {
// 	h.fullResponse += text
// 	h.responseChan <- text
// }
//
// func (h *tuiResponseHandler) FinalText(contextId int64, prompt string,
// 	response string) {
// 	h.fullResponse = response
//
// 	history := data.History{
// 		ContextId:    contextId,
// 		Prompt:       prompt,
// 		Response:     response,
// 		Abbreviation: "",
// 		TokenCount:   0,
// 	}
//
// 	_, err := h.Repository.InsertHistory(history)
// 	if err != nil {
// 		println(fmt.Sprintf("Error while trying to save history: %s", err))
// 	}
//
// 	code := services.ExtractCodeBlocks(response)
// 	allCode := strings.Join(code, "\n\n")
//
// 	err = clipboard.WriteAll(allCode)
// 	if err != nil {
// 		fmt.Printf("Error copying to clipboard: %v\n", err)
// 	}
//
// 	// Signal done BEFORE closing responseChan
// 	logger.Debug.Println("Final text in tui response channel")
// 	logger.Debug.Println("closing doneChan and responseChan")
// 	close(h.doneChan)
// 	close(h.responseChan)
// }


================================

FILE: ./tui/list_view.go
================================

package tui

import (
	"fmt"
	"strings"

	"github.com/atotto/clipboard"
	"github.com/charmbracelet/bubbles/textinput"
	tea "github.com/charmbracelet/bubbletea"
	"owl/data"
)

type listViewModel struct {
	shared        *sharedState
	cursor        int
	loading       bool
	viewport      int
	quitting      bool
	mode          listMode
	textInput     textinput.Model
	inputMode     inputMode
	showingPrompt bool
}

type listMode int
type inputMode int

const (
	normalMode listMode = iota
	confirmDeleteMode
	inputDialogMode
	showPromptMode
)

const (
	inputNewContext inputMode = iota
	inputSystemPrompt
)

type contextsLoadedMsg []contextItem
type contextCreatedMsg struct{ id int64 }
type contextDeletedMsg struct{}
type promptUpdatedMsg struct{}
type errorMsg struct{ err error }

func newListViewModel(config TUIConfig) *listViewModel {
	shared := &sharedState{
		config:   config,
		contexts: []contextItem{},
	}

	ti := textinput.New()
	ti.Placeholder = "Enter text..."
	ti.Focus()
	ti.CharLimit = 500
	ti.Width = 50

	return &listViewModel{
		shared:    shared,
		loading:   true,
		viewport:  0,
		mode:      normalMode,
		textInput: ti,
	}
}

func (m *listViewModel) Init() tea.Cmd {
	return m.loadContexts()
}

func (m *listViewModel) loadContexts() tea.Cmd {
	return func() tea.Msg {
		contexts, err := m.shared.config.Repository.GetAllContexts()
		if err != nil {
			return errorMsg{err}
		}

		items := make([]contextItem, len(contexts))
		for i, ctx := range contexts {
			history, _ := m.shared.config.Repository.GetHistoryByContextId(ctx.Id, 1000)
			items[i] = contextItem{
				context:      ctx,
				messageCount: len(history),
			}
		}

		return contextsLoadedMsg(items)
	}
}

func (m *listViewModel) createContext(name string) tea.Cmd {
	return func() tea.Msg {
		ctx := data.Context{Name: name}
		id, err := m.shared.config.Repository.InsertContext(ctx)
		if err != nil {
			return errorMsg{err}
		}
		return contextCreatedMsg{id}
	}
}

func (m *listViewModel) deleteContext(contextId int64) tea.Cmd {
	return func() tea.Msg {
		_, err := m.shared.config.Repository.DeleteContext(contextId)
		if err != nil {
			return errorMsg{err}
		}
		return contextDeletedMsg{}
	}
}

func (m *listViewModel) updateSystemPrompt(contextId int64, prompt string) tea.Cmd {
	return func() tea.Msg {
		err := m.shared.config.Repository.UpdateSystemPrompt(contextId, prompt)
		if err != nil {
			return errorMsg{err}
		}
		return promptUpdatedMsg{}
	}
}

func (m *listViewModel) Update(msg tea.Msg) (tea.Model, tea.Cmd) {
	switch msg := msg.(type) {
	case tea.KeyMsg:
		if m.loading {
			return m, nil
		}

		// Handle input dialog mode
		if m.mode == inputDialogMode {
			switch msg.String() {
			case "enter":
				value := m.textInput.Value()
				m.textInput.SetValue("")
				m.mode = normalMode

				if value != "" {
					switch m.inputMode {
					case inputNewContext:
						return m, tea.Sequence(
							m.createContext(value),
							m.loadContexts(),
						)
					case inputSystemPrompt:
						if len(m.shared.contexts) > 0 {
							contextId := m.shared.contexts[m.cursor].context.Id
							return m, tea.Sequence(
								m.updateSystemPrompt(contextId, value),
								m.loadContexts(),
							)
						}
					}
				}
				return m, nil

			case "esc":
				m.textInput.SetValue("")
				m.mode = normalMode
				return m, nil
			default:
				var cmd tea.Cmd
				m.textInput, cmd = m.textInput.Update(msg)
				return m, cmd
			}
		}

		// Handle confirm delete mode
		if m.mode == confirmDeleteMode {
			switch msg.String() {
			case "y", "Y":
				if len(m.shared.contexts) > 0 {
					contextId := m.shared.contexts[m.cursor].context.Id
					m.mode = normalMode
					if m.cursor >= len(m.shared.contexts)-1 && m.cursor > 0 {
						m.cursor--
					}
					return m, tea.Sequence(
						m.deleteContext(contextId),
						m.loadContexts(),
					)
				}
				m.mode = normalMode
				return m, nil
			case "n", "N", "esc":
				m.mode = normalMode
				return m, nil
			}
			return m, nil
		}

		// Handle show prompt mode
		if m.mode == showPromptMode {
			switch msg.String() {
			case "esc", "s", "q":
				m.mode = normalMode
				return m, nil
			}
			return m, nil
		}

		// Normal mode key handling
		switch msg.String() {
		case "ctrl+c", "q":
			m.quitting = true
			return m, tea.Quit

		case "up", "k":
			if m.cursor > 0 {
				m.cursor--
			}

		case "down", "j":
			if m.cursor < len(m.shared.contexts)-1 {
				m.cursor++
			}

		case "enter":
			// Open chat view for selected context
			if len(m.shared.contexts) > 0 {
				m.shared.selectedCtx = &m.shared.contexts[m.cursor].context
				chatView := newChatViewModel(m.shared)
				return chatView, tea.Sequence(
					chatView.Init(),
					func() tea.Msg {
						return tea.WindowSizeMsg{
							Width:  m.shared.width,
							Height: m.shared.height,
						}
					},
				)
			}

		case "c":
			// Copy command to clipboard
			if len(m.shared.contexts) > 0 {
				ctx := m.shared.contexts[m.cursor].context
				cmd := fmt.Sprintf("owl --context_name=\"%s\" --stream --history=10 --prompt='...", ctx.Name)
				clipboard.WriteAll(cmd)
			}

		case "n":
			// Create new context
			m.mode = inputDialogMode
			m.inputMode = inputNewContext
			m.textInput.Placeholder = "Enter context name..."
			m.textInput.Focus()

		case "p":
			// Set system prompt
			if len(m.shared.contexts) > 0 {
				m.mode = inputDialogMode
				m.inputMode = inputSystemPrompt
				currentPrompt := m.shared.contexts[m.cursor].context.SystemPrompt
				m.textInput.SetValue(currentPrompt)
				m.textInput.Placeholder = "Enter system prompt..."
				m.textInput.Focus()
			}

		case "s":
			// Show system prompt
			if len(m.shared.contexts) > 0 {
				m.mode = showPromptMode
			}

		case "d":
			// Delete context (with confirmation)
			if len(m.shared.contexts) > 0 {
				m.mode = confirmDeleteMode
			}

		case "r":
			// Refresh contexts
			m.loading = true
			return m, m.loadContexts()
		}

	case contextsLoadedMsg:
		m.shared.contexts = []contextItem(msg)
		m.loading = false

	case contextCreatedMsg:
		// Context created, will be loaded by loadContexts

	case contextDeletedMsg:
		// Context deleted, will be refreshed by loadContexts

	case promptUpdatedMsg:
		// Prompt updated, will be refreshed by loadContexts

	case errorMsg:
		m.shared.err = msg.err
		m.loading = false

	case tea.WindowSizeMsg:
		m.viewport = msg.Height
		m.shared.width = msg.Width
		m.shared.height = msg.Height
	}

	return m, nil
}

func (m *listViewModel) View() string {
	if m.quitting {
		return ""
	}

	if m.loading {
		return loadingStyle.Render("Loading contexts...")
	}

	if m.shared.err != nil {
		return errorStyle.Render(fmt.Sprintf("Error: %v", m.shared.err))
	}

	var b strings.Builder

	// Header
	b.WriteString(headerStyle.Render(" OWL Contexts"))
	b.WriteString("\n\n")

	// Show input dialog if in input mode
	if m.mode == inputDialogMode {
		title := "Create New Context"
		if m.inputMode == inputSystemPrompt {
			title = "Set System Prompt"
		}

		b.WriteString(headerStyle.Render(title))
		b.WriteString("\n\n")
		b.WriteString(m.textInput.View())
		b.WriteString("\n\n")
		b.WriteString(helpStyle.Render("enter: confirm  esc: cancel"))
		return b.String()
	}

	// Show confirm delete dialog
	if m.mode == confirmDeleteMode && len(m.shared.contexts) > 0 {
		ctx := m.shared.contexts[m.cursor].context
		b.WriteString(errorStyle.Render(fmt.Sprintf("Delete context '%s'?", ctx.Name)))
		b.WriteString("\n\n")
		b.WriteString(helpStyle.Render("y: yes  n: no  esc: cancel"))
		return b.String()
	}

	// Show system prompt modal
	if m.mode == showPromptMode && len(m.shared.contexts) > 0 {
		ctx := m.shared.contexts[m.cursor].context
		b.WriteString(headerStyle.Render(fmt.Sprintf("System Prompt: %s", ctx.Name)))
		b.WriteString("\n\n")

		if ctx.SystemPrompt == "" {
			b.WriteString(dimStyle.Render("No system prompt set"))
		} else {
			b.WriteString(itemStyle.Render(ctx.SystemPrompt))
		}

		b.WriteString("\n\n")
		b.WriteString(helpStyle.Render("esc/s/q: close"))
		return b.String()
	}

	// Context list (normal mode)
	if len(m.shared.contexts) == 0 {
		b.WriteString(dimStyle.Render("No contexts found. Press 'n' to create one."))
	} else {
		for i, item := range m.shared.contexts {
			cursor := " "
			style := itemStyle

			if i == m.cursor {
				cursor = ">"
				style = selectedItemStyle
			}

			line := fmt.Sprintf("%s %s (%d messages)",
				cursor,
				item.context.Name,
				item.messageCount,
			)

			if item.context.SystemPrompt != "" {
				preview := item.context.SystemPrompt
				if len(preview) > 40 {
					preview = preview[:40] + "..."
				}
				line += " " + dimStyle.Render(fmt.Sprintf("[%s]", preview))
			}

			b.WriteString(style.Render(line))
			b.WriteString("\n")
		}
	}

	// Footer
	b.WriteString("\n")
	b.WriteString(helpStyle.Render(
		"/k up  /j down  enter select  n new  p set prompt  s show prompt  d delete  c copy  r refresh  q quit",
	))

	return b.String()
}


================================

FILE: ./tui/models.go
================================

package tui

import (
	"owl/data"
)

type viewMode int

const (
	listView viewMode = iota
	chatView
)

type contextItem struct {
	context      data.Context
	messageCount int
}

// Shared state across views
type sharedState struct {
	config      TUIConfig
	contexts    []contextItem
	selectedCtx *data.Context
	err         error
	width       int
	height      int
}


================================

FILE: ./tui/styles.go
================================

package tui

import "github.com/charmbracelet/lipgloss"

var (
	primaryColor   = lipgloss.Color("63")
	secondaryColor = lipgloss.Color("240")
	accentColor    = lipgloss.Color("205")
	errorColor     = lipgloss.Color("196")

	headerStyle = lipgloss.NewStyle().
			Bold(true).
			Foreground(primaryColor).
			MarginBottom(1)

	itemStyle = lipgloss.NewStyle().
			PaddingLeft(2)

	selectedItemStyle = lipgloss.NewStyle().
				PaddingLeft(1).
				Foreground(accentColor).
				Bold(true)

	dimStyle = lipgloss.NewStyle().
			Foreground(secondaryColor)

	helpStyle = lipgloss.NewStyle().
			Foreground(secondaryColor).
			Italic(true).
			MarginTop(1)

	loadingStyle = lipgloss.NewStyle().
			Foreground(primaryColor).
			Bold(true)

	errorStyle = lipgloss.NewStyle().
			Foreground(errorColor).
			Bold(true)

	userPromptStyle = lipgloss.NewStyle().
			Foreground(accentColor).
			Bold(true)

	aiResponseStyle = lipgloss.NewStyle().
			PaddingLeft(2)

	sendingStyle = lipgloss.NewStyle().
			Foreground(primaryColor).
			Bold(true).
			Blink(true)
)


================================

FILE: ./tui/tui.go
================================

package tui

import (
	"owl/data"
	"owl/models"

	tea "github.com/charmbracelet/bubbletea"
)

type TUIConfig struct {
	Repository   data.HistoryRepository
	Model        models.Model
	HistoryCount int
}

// Run starts the TUI application
func Run(config TUIConfig) error {
	p := tea.NewProgram(
		initialModel(config),
		tea.WithAltScreen(),
	)

	_, err := p.Run()
	return err
}

func initialModel(config TUIConfig) tea.Model {
	return newListViewModel(config)
}


================================
Total files processed: 40
